{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cloud ML Engine for Tensorflow.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"GLwSsoRNO3hC","colab_type":"text"},"cell_type":"markdown","source":["# Getting Started"]},{"metadata":{"id":"Ufta5dNEPAZL","colab_type":"text"},"cell_type":"markdown","source":["Cloud Machine Learning Engine을 사용하기 전에 기계 학습 및 TensorFlow에 익숙해야합니다.\n","\n","기계 학습을 처음 사용하는 경우 다음 버튼을 선택하십시오.\n","\n","다음 자료는 기계 학습에 대해 학습하는 데 도움을 줄 수 있습니다.\n","\n","* [Intro to Machine Learning - Udacity video series](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkQXg8TkVdIvYv4HfLG7SiH&authuser=0&hl=ko)\n","* [Machine Learning - Coursera video series](https://www.youtube.com/watch?v=qeHZOdmJvFU&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&authuser=0&hl=ko)\n","* [Machine Learning - Stanford Course CS229 Videos](https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599&authuser=0&hl=ko)\n","* [Colah's Blog - Christopher Olah writes about machine learning](https://colah.github.io/)\n","\n","기계 학습에 익숙하지만 TensorFlow에 익숙하지 않은 경우 다음 버튼을 선택하십시오.\n","\n","* [Getting Started With TensorFlow](https://www.tensorflow.org/get_started/get_started?authuser=0&hl=ko)\n","* [TensorFlow Dev Summit 2017 Videos](https://www.youtube.com/playlist?list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv&authuser=0&hl=ko)\n","* [TensorFlow for Deep Learning Research - Stanford Course CS20si](https://www.stanford.edu/class/cs20si/)\n","\n","이전의 경험을 통해 또는 제안 된 리소스를 탐색하여 기계 학습 및 TensorFlow에 익숙해지면 이 연습을 시작할 준비가 된 것입니다."]},{"metadata":{"id":"s3-H3RMW2Khu","colab_type":"text"},"cell_type":"markdown","source":["* pricing : https://cloud.google.com/ml-engine/docs/pricing\n","* runtime version list : https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list"]},{"metadata":{"id":"MpG1-LwDPwpM","colab_type":"text"},"cell_type":"markdown","source":["## Overview\n","\n","이 문서는 Cloud Machine Learning Engine에 대한 교육 및 예측에 대한 포괄적 인 소개를 제공합니다. 인구 조사 데이터 세트를 사용하는 샘플을 통해 다음을 수행 할 것입니다.\n","\n","* TensorFlow trainer를 만들고 로컬에서 검증합니다.\n","* trainer를 클라우드의 단일 worker 인스턴스에서 실행\n","* trainer를 클라우드의 분산 된 학습 작업으로 실행\n","* 하이퍼 매개 변수 튜닝을 사용하여 하이퍼 매개 변수를 최적화\n","* 예측을 하기위한 모델 배포\n","* 온라인 예측을 요청하고 응답을보십시오.\n","* 배치 예측 요청"]},{"metadata":{"id":"xWQcV_cCGMBb","colab_type":"text"},"cell_type":"markdown","source":["## What you will build\n","\n","이 샘플은 미국 인구 통계 소득 데이터 세트를 기반으로 소득 카테고리를 예측하기위한 폭 넓고 깊은 모델을 구성합니다.\n","\n","Wide&deepa모델은 심층 신경망 (DNN)을 사용하여 복잡한 피쳐 또는 이러한 피쳐 간의 상호 작용에 대한 높은 수준의 추상화를 학습합니다. 그런 다음 이 모델은 DNN의 출력을 더 간단한 피쳐에서 수행 된 선형 회귀와 결합합니다. 이는 많은 구조화 된 데이터 문제에 효과적인 성능과 속도 사이의 균형을 제공합니다.\n","\n","wide&deep 모델에 대한 자세한 내용은 Google Research 블로그 게시물의 [Wide & Deep Learning : TensorFlow와 함께하면 더 좋습니다](https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html).\n","\n","이 샘플에서는 TensorFlow의 미리 작성된 DNNCombinedLinearClassifier 클래스를 사용하여 모델을 정의하고 이러한 (잠재적으로) 변환 된 기능을 DNN 또는 모델의 선형 부분에 할당하기 전에 데이터 세트에 특정한 데이터 변환 만 정의하면됩니다."]},{"metadata":{"id":"HVGStS2-GwpC","colab_type":"text"},"cell_type":"markdown","source":["## Costs\n","\n","이 연습에서는 다음과 같은 Google Cloud Platform의 청구 가능 구성 요소를 사용합니다.\n","\n","* 클라우드 머신 학습 엔진 :\n","  * 학습\n","  * 예측\n","* Google Cloud Storage for :\n","  * 학습용 입력 데이터 저장\n","  * trainer 패키지 준비\n","  * 학습 artifacts 작성\n","  * 배치 예측을 위한 입력 데이터 파일 저장\n","\n","[가격 계산기](https://cloud.google.com/products/calculator/?authuser=0&hl=ko)를 사용하여 예상 사용량을 기반으로 비용 견적을 생성하십시오."]},{"metadata":{"id":"wlWB2QkTHK3k","colab_type":"text"},"cell_type":"markdown","source":["## Set up and test your Cloud environment\n","\n","GCP 계정을 설정하고 Cloud ML 엔진 API를 활성화 한 다음 Cloud SDK를 설치하고 활성화하려면 다음 단계를 완료하십시오."]},{"metadata":{"id":"3hzy0tlkHPUT","colab_type":"text"},"cell_type":"markdown","source":["### Set up your GCP project\n","\n","1. Select or create a GCP project.\n","2. 프로젝트에 결제가 사용 설정되어 있는지 확인하세요.\n","3. Enable the Cloud Machine Learning Engine and Compute Engine APIs.\n","4. Set up authentication:\n","  1. Go to the Create service account key page in the GCP Console.\n","  2. From the Service account drop-down list, select New service account.\n","  3. Enter a name into the Service account name field.\n","  4. From the Role drop-down list, select Project > Owner.\n","  5. Click Create. A JSON file that contains your key downloads to your computer.\n","  \n","5. Set the environment variable GOOGLE_APPLICATION_CREDENTIALS to the file path of the JSON file that contains your service account key.\n","6. Install and initialize the Cloud SDK.\n","\n","#### Set up your environment\n","MacOS 또는 Cloud Shell의 원격 환경에서 환경을 로컬로 설정하려면 아래 옵션 중 하나를 선택하십시오.\n","\n","macOS 사용자의 경우 아래의 MACOS 탭을 사용하여 환경을 설정하는 것이 좋습니다. CLOSED SHELL 탭에 표시된 Cloud Shell은 macOS, Linux 및 Windows에서 사용할 수 있습니다. Cloud Shell은 Cloud Machine Learning Engine을 빠르게 사용할 수는 있지만 지속적인 개발 작업에는 적합하지 않습니다."]},{"metadata":{"id":"UpcCGUNtHzRK","colab_type":"text"},"cell_type":"markdown","source":["1. Install a virtual environment to create an isolated Python development environment for this guide. For example, the following commands install virtualenv and activate an environment named cmle-env."]},{"metadata":{"id":"RrgqJ23hOzwR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":70},"outputId":"272fc978-3b2c-4a64-dd0f-c17f0b2157d6","executionInfo":{"status":"ok","timestamp":1525336206482,"user_tz":-540,"elapsed":2953,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!virtualenv cmle-env\n","!source cmle-env/bin/activate"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/bin/sh: 1: virtualenv: not found\n","/bin/sh: 1: source: not found\n"],"name":"stdout"}]},{"metadata":{"id":"-wT_xEFrH8ev","colab_type":"text"},"cell_type":"markdown","source":["2. Confirm that you have Python installed and, if necessary, install it."]},{"metadata":{"id":"Y8JDACV9H2DP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"dedc24e6-b628-4a3b-af33-6b7f2ae86190","executionInfo":{"status":"ok","timestamp":1525336262194,"user_tz":-540,"elapsed":1794,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!python -V"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Python 3.6.3\r\n"],"name":"stdout"}]},{"metadata":{"id":"t1grEgowIC8N","colab_type":"text"},"cell_type":"markdown","source":["3. Install pip, Python’s package manager. Check if you already have pip installed by running pip --version. Ensure that you have the latest version of pip and if not, upgrade it using the following command:"]},{"metadata":{"id":"IGw7EdGMH-d-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"89753628-a960-45f2-e5b1-3c075c4eb5fb","executionInfo":{"status":"ok","timestamp":1525336273999,"user_tz":-540,"elapsed":2835,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!pip install -U pip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (10.0.1)\r\n"],"name":"stdout"}]},{"metadata":{"id":"x5x3i1KuIIu2","colab_type":"text"},"cell_type":"markdown","source":["### Verify the Google Cloud SDK components\n","\n","To verify that the Google Cloud SDK components are installed:\n","\n","1. List your models:"]},{"metadata":{"id":"zPEeY3EAIUdO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b0KN_ZVAIGj9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":70},"outputId":"75fd952c-ccf3-4b92-a037-c847fb551994","executionInfo":{"status":"ok","timestamp":1525407983404,"user_tz":-540,"elapsed":3959,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud config set compute/region us-east1\n","!gcloud config set project cpb100-182208"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Updated property [compute/region].\n","Updated property [core/project].\n"],"name":"stdout"}]},{"metadata":{"id":"4vZuwIACIgjb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":70},"outputId":"81eed97b-146e-40e5-c081-35eef9131307","executionInfo":{"status":"ok","timestamp":1525407986229,"user_tz":-540,"elapsed":2768,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine models list"],"execution_count":3,"outputs":[{"output_type":"stream","text":["NAME      DEFAULT_VERSION_NAME\r\n","taxifare  v1\r\n"],"name":"stdout"}]},{"metadata":{"id":"oYwVD1EMIpTi","colab_type":"text"},"cell_type":"markdown","source":["#### Install TensorFlow\n","\n","To install TensorFlow, run the following command:"]},{"metadata":{"id":"EtcO589aItVR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":500},"outputId":"fd9e0990-96e0-410d-ca83-74a23ea3d9cd","executionInfo":{"status":"ok","timestamp":1525336459462,"user_tz":-540,"elapsed":25656,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!pip install --upgrade tensorflow"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n","\u001b[K    100% |████████████████████████████████| 49.1MB 1.0MB/s \n","\u001b[?25hRequirement not upgraded as not directly required: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n","Requirement not upgraded as not directly required: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement not upgraded as not directly required: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.31.0)\n","Requirement not upgraded as not directly required: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement not upgraded as not directly required: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n","\u001b[K    100% |████████████████████████████████| 3.1MB 8.6MB/s \n","\u001b[?25hRequirement not upgraded as not directly required: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.3)\n","Requirement not upgraded as not directly required: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.5.2.post1)\n","Requirement not upgraded as not directly required: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n","Requirement not upgraded as not directly required: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.6.2)\n","Requirement not upgraded as not directly required: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (2.6.11)\n","Requirement not upgraded as not directly required: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (1.5.0)\n","Requirement not upgraded as not directly required: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (0.14.1)\n","Requirement not upgraded as not directly required: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (0.9999999)\n","Requirement not upgraded as not directly required: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow) (39.1.0)\n","Installing collected packages: tensorboard, tensorflow\n","  Found existing installation: tensorboard 1.7.0\n","    Uninstalling tensorboard-1.7.0:\n","      Successfully uninstalled tensorboard-1.7.0\n","  Found existing installation: tensorflow 1.7.0\n","    Uninstalling tensorflow-1.7.0:\n","      Successfully uninstalled tensorflow-1.7.0\n","Successfully installed tensorboard-1.8.0 tensorflow-1.8.0\n"],"name":"stdout"}]},{"metadata":{"id":"eLP3cPKJIzQQ","colab_type":"text"},"cell_type":"markdown","source":["For more information about installing TensorFlow, see the [TensorFlow documentation](https://www.tensorflow.org/install/?authuser=0&hl=ko).\n","\n","To troubleshoot your TensorFlow installation, see [TensorFlow's guide to common installation problems](https://www.tensorflow.org/install/install_mac?authuser=0&hl=ko#common_installation_problems)."]},{"metadata":{"id":"Epc8WNoUI-Nd","colab_type":"text"},"cell_type":"markdown","source":["#### Run a simple TensorFlow Python program\n","\n","Run a simple Python program to test your installation of TensorFlow. If you are using Cloud Shell, note that TensorFlow is already installed."]},{"metadata":{"id":"xCKBRSJKJB-p","colab_type":"text"},"cell_type":"markdown","source":["1. Start a Python interactive shell."]},{"metadata":{"id":"6RZYks5_IPP0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!echo \"import tensorflow as tf\\n\\\n","hello=tf.constant('Hello, TensorFlow!')\\n\\\n","sess=tf.Session()\\n\\\n","print(sess.run(hello))\" > hello_tf.py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iwm8vEQsJDyv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":103},"outputId":"a9f11f2f-0cf1-4837-ba71-fb5af4219423","executionInfo":{"status":"ok","timestamp":1525336663610,"user_tz":-540,"elapsed":3941,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!python hello_tf.py"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n","  from ._conv import register_converters as _register_converters\n","2018-05-03 08:37:44.364682: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","b'Hello, TensorFlow!'\n"],"name":"stdout"}]},{"metadata":{"id":"oVyUF3FwJuzD","colab_type":"text"},"cell_type":"markdown","source":["## Python version support\n","\n","Cloud ML Engine runs Python 2.7 by default, and the sample for this tutorial uses Python 2.7.\n","\n","Python 3.5 is available for training when you use Cloud ML Engine runtime version 1.4 or greater. Online and batch prediction work with trained models, regardless of whether they were trained using Python 2 or Python 3.\n","\n","Cloud ML Engine   Documentation   TensorFlow\n","Getting Started\n","\n","목차\n","Overview\n","What you will build\n","Costs\n","Set up and test your Cloud environment\n","\n","Before using Cloud Machine Learning Engine, you should be familiar with machine learning and TensorFlow.\n","\n","If you're new to machine learning, select the following button.\n","\n","LEARN ABOUT MACHINE LEARNING\n","The following resources can help you learn about machine learning:\n","\n","Intro to Machine Learning - Udacity video series\n","Machine Learning - Coursera video series\n","Machine Learning - Stanford Course CS229 Videos\n","Colah's Blog - Christopher Olah writes about machine learning\n","If you're familiar with machine learning, but new to TensorFlow, select the following button.\n","\n","LEARN ABOUT TENSORFLOW\n","The following resources can help you learn about TensorFlow:\n","\n","Getting Started With TensorFlow\n","TensorFlow Dev Summit 2017 Videos\n","TensorFlow for Deep Learning Research - Stanford Course CS20si\n","Once you're familiar with machine learning and TensorFlow, either through prior experience or by exploring the suggested resources, you're ready to get started with this walkthrough.\n","\n","Overview\n","\n","This document provides an introductory, end-to-end walkthrough of training and prediction on Cloud Machine Learning Engine. You will walk through a sample that uses a census dataset to:\n","\n","Create a TensorFlow trainer and validate it locally.\n","Run your trainer on a single worker instance in the cloud.\n","Run your trainer as a distributed training job in the cloud.\n","Optimize your hyperparameters by using hyperparameter tuning.\n","Deploy a model to support prediction.\n","Request an online prediction and see the response.\n","Request a batch prediction.\n","What you will build\n","\n","The sample builds a wide and deep model for predicting income category based on United States Census Income Dataset.\n","\n","Wide and deep models use deep neural nets (DNNs) to learn high level abstractions about complex features or interactions between such features. These models then combine the outputs from the DNN with a linear regression performed on simpler features. This provides a balance between power and speed that is effective on many structured data problems.\n","\n","You can read more about wide and deep models in the Google Research Blog post named Wide & Deep Learning: Better Together with TensorFlow.\n","\n","The sample defines the model using TensorFlow's prebuilt DNNCombinedLinearClassifier class, and need only define the data transformations particular to our dataset before assigning these (potentially) transformed features to either the DNN or the linear portion of the model.\n","\n","Costs\n","\n","This walkthrough uses billable components of Google Cloud Platform, including:\n","\n","Cloud Machine Learning Engine for:\n","Training\n","Prediction\n","Google Cloud Storage for:\n","Storing input data for training\n","Staging the trainer package\n","Writing training artifacts\n","Storing input data files for batch prediction\n","Use the Pricing Calculator to generate a cost estimate based on your projected usage.\n","\n","Set up and test your Cloud environment\n","\n","Complete the following steps to set up a GCP account, activate the Cloud ML Engine API, and install and activate the Cloud SDK.\n","\n","Set up your GCP project\n","\n","Select or create a GCP project.\n","\n","GO TO THE MANAGE RESOURCES PAGE\n","프로젝트에 결제가 사용 설정되어 있는지 확인하세요.\n","\n","결제 사용 설정 방법 알아보기\n","Enable the Cloud Machine Learning Engine and Compute Engine APIs.\n","ENABLE THE APIS\n","Set up authentication:\n","Go to the Create service account key page in the GCP Console.\n","\n","GO TO THE CREATE SERVICE ACCOUNT KEY PAGE\n","From the Service account drop-down list, select New service account.\n","Enter a name into the Service account name field.\n","From the Role drop-down list, select Project > Owner.\n","\n","Note: The Role field authorizes your service account to access resources. You can view and change this field later using GCP Console. If you are developing a production application, specify more granular permissions than Project > Owner. For more information, see granting roles to service accounts.\n","Click Create. A JSON file that contains your key downloads to your computer.\n","Set the environment variable GOOGLE_APPLICATION_CREDENTIALS to the file path of the JSON file that contains your service account key.\n","\n","▸\n","Example: Linux or macOS\n","\n","▸\n","Example: Windows\n","\n","Install and initialize the Cloud SDK.\n","Set up your environment\n","\n","Choose one of the options below to set up your environment locally on macOS or in a remote environment on Cloud Shell.\n","\n","For macOS users, we recommend that you set up your environment using the MACOS tab below. Cloud Shell, shown on the CLOUD SHELL tab, is available on macOS, Linux, and Windows. Cloud Shell provides a quick way to try Cloud Machine Learning Engine, but isn’t suitable for ongoing development work.\n","\n","MACOSCLOUD SHELL\n","Install a virtual environment to create an isolated Python development environment for this guide. For example, the following commands install virtualenv and activate an environment named cmle-env.\n","\n","virtualenv cmle-env\n","source cmle-env/bin/activate\n","Confirm that you have Python installed and, if necessary, install it.\n","\n","python -V\n","Install pip, Python’s package manager. Check if you already have pip installed by running pip --version. Ensure that you have the latest version of pip and if not, upgrade it using the following command:\n","\n","pip install -U pip\n","Verify the Google Cloud SDK components\n","\n","To verify that the Google Cloud SDK components are installed:\n","\n","List your models:\n","\n","gcloud ml-engine models list\n","If you have not created any models before, the command returns an empty list:\n","\n","Listed 0 items.\n","After you start creating models, you can see them listed by using this command.\n","Install TensorFlow\n","\n","To install TensorFlow, run the following command:\n","\n","pip install --upgrade tensorflow\n","For more information about installing TensorFlow, see the TensorFlow documentation.\n","\n","To troubleshoot your TensorFlow installation, see TensorFlow's guide to common installation problems.\n","\n","Run a simple TensorFlow Python program\n","\n","Run a simple Python program to test your installation of TensorFlow. If you are using Cloud Shell, note that TensorFlow is already installed.\n","\n","Start a Python interactive shell.\n","\n","python\n","Import TensorFlow.\n","\n",">>> import tensorflow as tf\n","Create a constant that contains a string.\n","\n",">>> hello = tf.constant('Hello, TensorFlow!')\n","Create a TensorFlow session.\n","\n",">>> sess = tf.Session()\n","You can ignore the warnings that the TensorFlow library wasn't compiled to use certain instructions.\n","Display the value of hello.\n","\n",">>> print(sess.run(hello))\n","If successful, the system outputs:\n","\n","Hello, TensorFlow!\n","Stop the Python interactive shell.\n","\n",">>> exit()\n","Python version support\n","\n","Cloud ML Engine runs Python 2.7 by default, and the sample for this tutorial uses Python 2.7.\n","\n","Python 3.5 is available for training when you use Cloud ML Engine runtime version 1.4 or greater. Online and batch prediction work with trained models, regardless of whether they were trained using Python 2 or Python 3.\n","\n","See how to [submit a training job using Python 3.5.](https://cloud.google.com/ml-engine/docs/tensorflow/versioning?authuser=0&hl=ko#set-python-version-training)"]},{"metadata":{"id":"tH38862sJ8iN","colab_type":"text"},"cell_type":"markdown","source":["## Download the code for this tutorial\n","\n","1. Download the sample from the GitHub repository.\n","  1. Download and extract [the Cloud ML Engine sample zip file](https://github.com/GoogleCloudPlatform/cloudml-samples/archive/master.zip).\n","  2. Open a terminal window and navigate to the directory that contains the extracted cloudml-samples-master directory.\n","  3. Navigate to the cloudml-samples-master > census > estimator directory. The commands in this walkthrough must be run from the estimator directory."]},{"metadata":{"id":"EuaPjJUbJiKb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":302},"outputId":"00dc97f5-7230-44ba-95a5-36143a81b680","executionInfo":{"status":"ok","timestamp":1525408008009,"user_tz":-540,"elapsed":2327,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!wget https://github.com/GoogleCloudPlatform/cloudml-samples/archive/master.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2018-05-04 04:26:47--  https://github.com/GoogleCloudPlatform/cloudml-samples/archive/master.zip\r\n","Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n","Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://codeload.github.com/GoogleCloudPlatform/cloudml-samples/zip/master [following]\n","--2018-05-04 04:26:47--  https://codeload.github.com/GoogleCloudPlatform/cloudml-samples/zip/master\n","Resolving codeload.github.com (codeload.github.com)... 192.30.253.121, 192.30.253.120\n","Connecting to codeload.github.com (codeload.github.com)|192.30.253.121|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 24169711 (23M) [application/zip]\n","Saving to: ‘master.zip’\n","\n","master.zip          100%[===================>]  23.05M  65.4MB/s    in 0.4s    \n","\n","2018-05-04 04:26:47 (65.4 MB/s) - ‘master.zip’ saved [24169711/24169711]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"5bwSZLJHKOj4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":4069},"outputId":"27a2ad51-4f7e-49fa-c9da-7333b741bcaf","executionInfo":{"status":"ok","timestamp":1525408010601,"user_tz":-540,"elapsed":2514,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!unzip master.zip"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Archive:  master.zip\r\n","8a349c10bc19c1fe42bd6bd83606cec3a23b8f76\r\n","   creating: cloudml-samples-master/\r\n","  inflating: cloudml-samples-master/CONTRIBUTING.md  \r\n","  inflating: cloudml-samples-master/ISSUE_TEMPLATE.md  \r\n","  inflating: cloudml-samples-master/LICENSE  \r\n","  inflating: cloudml-samples-master/README.md  \r\n","  inflating: cloudml-samples-master/TESTING.md  \r\n","   creating: cloudml-samples-master/census/\r\n","  inflating: cloudml-samples-master/census/README.md  \r\n","   creating: cloudml-samples-master/census/customestimator/\r\n","   creating: cloudml-samples-master/census/customestimator/trainer/\r\n"," extracting: cloudml-samples-master/census/customestimator/trainer/__init__.py  \r\n","  inflating: cloudml-samples-master/census/customestimator/trainer/model.py  \r\n","  inflating: cloudml-samples-master/census/customestimator/trainer/task.py  \r\n","   creating: cloudml-samples-master/census/estimator/\r\n","   creating: cloudml-samples-master/census/estimator/trainer/\r\n"," extracting: cloudml-samples-master/census/estimator/trainer/__init__.py  \r\n","  inflating: cloudml-samples-master/census/estimator/trainer/model.py  \r\n","  inflating: cloudml-samples-master/census/estimator/trainer/task.py  \r\n","  inflating: cloudml-samples-master/census/hptuning_config.yaml  \r\n","   creating: cloudml-samples-master/census/keras/\r\n","  inflating: cloudml-samples-master/census/keras/README.md  \r\n","  inflating: cloudml-samples-master/census/keras/preprocess.py  \r\n","  inflating: cloudml-samples-master/census/keras/requirements.txt  \r\n","  inflating: cloudml-samples-master/census/keras/setup.py  \r\n","   creating: cloudml-samples-master/census/keras/trainer/\r\n"," extracting: cloudml-samples-master/census/keras/trainer/__init__.py  \r\n","  inflating: cloudml-samples-master/census/keras/trainer/model.py  \r\n","  inflating: cloudml-samples-master/census/keras/trainer/task.py  \r\n"," extracting: cloudml-samples-master/census/requirements.txt  \r\n","  inflating: cloudml-samples-master/census/sample.sh  \r\n","   creating: cloudml-samples-master/census/tensorflowcore/\r\n","   creating: cloudml-samples-master/census/tensorflowcore/trainer/\r\n"," extracting: cloudml-samples-master/census/tensorflowcore/trainer/__init__.py  \r\n","  inflating: cloudml-samples-master/census/tensorflowcore/trainer/model.py  \r\n","  inflating: cloudml-samples-master/census/tensorflowcore/trainer/task.py  \r\n","  inflating: cloudml-samples-master/census/test.csv  \r\n","  inflating: cloudml-samples-master/census/test.json  \r\n","   creating: cloudml-samples-master/cloudml-template/\r\n","  inflating: cloudml-samples-master/cloudml-template/.gitignore  \r\n","  inflating: cloudml-samples-master/cloudml-template/README.md  \r\n","   creating: cloudml-samples-master/cloudml-template/examples/\r\n","   creating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/\r\n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/config.yaml  \r\n","   creating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/data/\n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/data/eval-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/data/train-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/setup.py  \n","   creating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/trainer/\n"," extracting: cloudml-samples-master/cloudml-template/examples/babyweight-custom/trainer/__init__.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/trainer/featurizer.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/trainer/input.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/trainer/metadata.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/trainer/model.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/babyweight-custom/trainer/task.py  \n","   creating: cloudml-samples-master/cloudml-template/examples/census-classification/\n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/config.yaml  \n","   creating: cloudml-samples-master/cloudml-template/examples/census-classification/data/\n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/data/eval-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/data/new-data.json  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/data/train-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/data/train-data-02.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/setup.py  \n","   creating: cloudml-samples-master/cloudml-template/examples/census-classification/trainer/\n"," extracting: cloudml-samples-master/cloudml-template/examples/census-classification/trainer/__init__.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/trainer/featurizer.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/trainer/input.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/trainer/metadata.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/trainer/model.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/census-classification/trainer/task.py  \n","   creating: cloudml-samples-master/cloudml-template/examples/german-custom/\n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/config.yaml  \n","   creating: cloudml-samples-master/cloudml-template/examples/german-custom/data/\n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/data/eval-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/data/train-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/data/train-data-02.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/data/train-data-03.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/data/train-data-04.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/setup.py  \n","   creating: cloudml-samples-master/cloudml-template/examples/german-custom/trainer/\n"," extracting: cloudml-samples-master/cloudml-template/examples/german-custom/trainer/__init__.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/trainer/featurizer.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/trainer/input.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/trainer/metadata.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/trainer/model.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/german-custom/trainer/task.py  \n","   creating: cloudml-samples-master/cloudml-template/examples/housing-regression/\n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/config.yaml  \n","   creating: cloudml-samples-master/cloudml-template/examples/housing-regression/data/\n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/data/eval-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/data/new-data.json  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/data/stats.json  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/data/train-data-01.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/data/train-data-02.csv  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/setup.py  \n","   creating: cloudml-samples-master/cloudml-template/examples/housing-regression/trainer/\n"," extracting: cloudml-samples-master/cloudml-template/examples/housing-regression/trainer/__init__.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/trainer/featurizer.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/trainer/input.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/trainer/metadata.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/trainer/model.py  \n","  inflating: cloudml-samples-master/cloudml-template/examples/housing-regression/trainer/task.py  \n","   creating: cloudml-samples-master/cloudml-template/scripts/\n","  inflating: cloudml-samples-master/cloudml-template/scripts/cloudml-deploy-model.sh  \n","  inflating: cloudml-samples-master/cloudml-template/scripts/cloudml-submit-train-job.sh  \n","  inflating: cloudml-samples-master/cloudml-template/scripts/config.yaml  \n","  inflating: cloudml-samples-master/cloudml-template/scripts/local-train.sh  \n","   creating: cloudml-samples-master/cloudml-template/template/\n","  inflating: cloudml-samples-master/cloudml-template/template/config.yaml  \n","  inflating: cloudml-samples-master/cloudml-template/template/inference.py  \n","  inflating: cloudml-samples-master/cloudml-template/template/setup.py  \n","   creating: cloudml-samples-master/cloudml-template/template/trainer/\n"," extracting: cloudml-samples-master/cloudml-template/template/trainer/__init__.py  \n","  inflating: cloudml-samples-master/cloudml-template/template/trainer/featurizer.py  \n","  inflating: cloudml-samples-master/cloudml-template/template/trainer/input.py  \n","  inflating: cloudml-samples-master/cloudml-template/template/trainer/metadata.py  \n","  inflating: cloudml-samples-master/cloudml-template/template/trainer/model.py  \n","  inflating: cloudml-samples-master/cloudml-template/template/trainer/task.py  \n","   creating: cloudml-samples-master/contrib/\n","  inflating: cloudml-samples-master/contrib/README.md  \n","   creating: cloudml-samples-master/criteo_tft/\n","  inflating: cloudml-samples-master/criteo_tft/README.md  \n"," extracting: cloudml-samples-master/criteo_tft/__init__.py  \n","  inflating: cloudml-samples-master/criteo_tft/config-large.yaml  \n"," extracting: cloudml-samples-master/criteo_tft/config-single.yaml  \n","  inflating: cloudml-samples-master/criteo_tft/config-small.yaml  \n","  inflating: cloudml-samples-master/criteo_tft/criteo.py  \n","  inflating: cloudml-samples-master/criteo_tft/path_constants.py  \n","  inflating: cloudml-samples-master/criteo_tft/preprocess.py  \n","  inflating: cloudml-samples-master/criteo_tft/requirements.txt  \n","  inflating: cloudml-samples-master/criteo_tft/setup.py  \n","   creating: cloudml-samples-master/criteo_tft/trainer/\n"," extracting: cloudml-samples-master/criteo_tft/trainer/__init__.py  \n","  inflating: cloudml-samples-master/criteo_tft/trainer/task.py  \n","   creating: cloudml-samples-master/flowers/\n","  inflating: cloudml-samples-master/flowers/README.md  \n","  inflating: cloudml-samples-master/flowers/__init__.py  \n","  inflating: cloudml-samples-master/flowers/images_to_json.py  \n","  inflating: cloudml-samples-master/flowers/pipeline.py  \n","  inflating: cloudml-samples-master/flowers/requirements.txt  \n","  inflating: cloudml-samples-master/flowers/sample.sh  \n","  inflating: cloudml-samples-master/flowers/setup.py  \n","   creating: cloudml-samples-master/flowers/trainer/\n","  inflating: cloudml-samples-master/flowers/trainer/__init__.py  \n","  inflating: cloudml-samples-master/flowers/trainer/model.py  \n","  inflating: cloudml-samples-master/flowers/trainer/preprocess.py  \n","  inflating: cloudml-samples-master/flowers/trainer/task.py  \n","  inflating: cloudml-samples-master/flowers/trainer/util.py  \n","   creating: cloudml-samples-master/iris/\n","  inflating: cloudml-samples-master/iris/README.md  \n","  inflating: cloudml-samples-master/iris/data_predict.csv  \n","  inflating: cloudml-samples-master/iris/pipeline.py  \n","  inflating: cloudml-samples-master/iris/preprocess.py  \n","  inflating: cloudml-samples-master/iris/setup.py  \n","   creating: cloudml-samples-master/iris/trainer/\n","  inflating: cloudml-samples-master/iris/trainer/__init__.py  \n","  inflating: cloudml-samples-master/iris/trainer/model.py  \n","  inflating: cloudml-samples-master/iris/trainer/task.py  \n","  inflating: cloudml-samples-master/iris/trainer/util.py  \n","   creating: cloudml-samples-master/mnist/\n","  inflating: cloudml-samples-master/mnist/README.md  \n","   creating: cloudml-samples-master/mnist/deployable/\n","   creating: cloudml-samples-master/mnist/deployable/data/\n","  inflating: cloudml-samples-master/mnist/deployable/data/eval_sample.tensor.json  \n","  inflating: cloudml-samples-master/mnist/deployable/data/predict_sample.tensor.json  \n","  inflating: cloudml-samples-master/mnist/deployable/setup.py  \n","   creating: cloudml-samples-master/mnist/deployable/trainer/\n","  inflating: cloudml-samples-master/mnist/deployable/trainer/__init__.py  \n","  inflating: cloudml-samples-master/mnist/deployable/trainer/input_data.py  \n","  inflating: cloudml-samples-master/mnist/deployable/trainer/task.py  \n","   creating: cloudml-samples-master/mnist/distributed/\n","   creating: cloudml-samples-master/mnist/distributed/data/\n","  inflating: cloudml-samples-master/mnist/distributed/data/eval_sample.tensor.json  \n","  inflating: cloudml-samples-master/mnist/distributed/data/eval_sample.tfrecord  \n","  inflating: cloudml-samples-master/mnist/distributed/local_predict.py  \n","  inflating: cloudml-samples-master/mnist/distributed/setup.py  \n","   creating: cloudml-samples-master/mnist/distributed/trainer/\n","  inflating: cloudml-samples-master/mnist/distributed/trainer/__init__.py  \n","  inflating: cloudml-samples-master/mnist/distributed/trainer/model.py  \n","  inflating: cloudml-samples-master/mnist/distributed/trainer/task.py  \n","  inflating: cloudml-samples-master/mnist/distributed/trainer/util.py  \n","   creating: cloudml-samples-master/mnist/hptuning/\n","  inflating: cloudml-samples-master/mnist/hptuning/setup.py  \n","   creating: cloudml-samples-master/mnist/hptuning/trainer/\n","  inflating: cloudml-samples-master/mnist/hptuning/trainer/__init__.py  \n","  inflating: cloudml-samples-master/mnist/hptuning/trainer/model.py  \n","  inflating: cloudml-samples-master/mnist/hptuning/trainer/task.py  \n","  inflating: cloudml-samples-master/mnist/hptuning/trainer/util.py  \n","   creating: cloudml-samples-master/mnist/trainable/\n","  inflating: cloudml-samples-master/mnist/trainable/setup.py  \n","   creating: cloudml-samples-master/mnist/trainable/trainer/\n","  inflating: cloudml-samples-master/mnist/trainable/trainer/__init__.py  \n","  inflating: cloudml-samples-master/mnist/trainable/trainer/task.py  \n","   creating: cloudml-samples-master/movielens/\n","  inflating: cloudml-samples-master/movielens/README.md  \n"," extracting: cloudml-samples-master/movielens/__init__.py  \n","  inflating: cloudml-samples-master/movielens/config.yaml  \n","  inflating: cloudml-samples-master/movielens/config_hypertune.yaml  \n","   creating: cloudml-samples-master/movielens/preproc/\n"," extracting: cloudml-samples-master/movielens/preproc/__init__.py  \n","  inflating: cloudml-samples-master/movielens/preproc/movielens.py  \n","  inflating: cloudml-samples-master/movielens/preprocess.py  \n","  inflating: cloudml-samples-master/movielens/requirements.txt  \n","  inflating: cloudml-samples-master/movielens/setup.py  \n","   creating: cloudml-samples-master/movielens/trainer/\n"," extracting: cloudml-samples-master/movielens/trainer/__init__.py  \n","  inflating: cloudml-samples-master/movielens/trainer/task.py  \n","   creating: cloudml-samples-master/reddit_tft/\n","  inflating: cloudml-samples-master/reddit_tft/README.md  \n"," extracting: cloudml-samples-master/reddit_tft/__init__.py  \n","  inflating: cloudml-samples-master/reddit_tft/config-small.yaml  \n","  inflating: cloudml-samples-master/reddit_tft/path_constants.py  \n","  inflating: cloudml-samples-master/reddit_tft/preprocess.py  \n","  inflating: cloudml-samples-master/reddit_tft/reddit.py  \n","  inflating: cloudml-samples-master/reddit_tft/requirements.txt  \n","  inflating: cloudml-samples-master/reddit_tft/setup.py  \n","   creating: cloudml-samples-master/reddit_tft/trainer/\n"," extracting: cloudml-samples-master/reddit_tft/trainer/__init__.py  \n","  inflating: cloudml-samples-master/reddit_tft/trainer/task.py  \n","   creating: cloudml-samples-master/sklearn/\n","   creating: cloudml-samples-master/sklearn/notebooks/\n","  inflating: cloudml-samples-master/sklearn/notebooks/Online Prediction with scikit-learn.ipynb  \n","   creating: cloudml-samples-master/testing/\n","   creating: cloudml-samples-master/testing/ubuntu/\n","   creating: cloudml-samples-master/testing/ubuntu/presubmit/\n","  inflating: cloudml-samples-master/testing/ubuntu/presubmit/census.cfg  \n","  inflating: cloudml-samples-master/testing/ubuntu/presubmit/common.cfg  \n","  inflating: cloudml-samples-master/testing/ubuntu/presubmit/flowers.cfg  \n","  inflating: cloudml-samples-master/testing/ubuntu/presubmit/run_if_changed.sh  \n","   creating: cloudml-samples-master/testing/ubuntu/release/\n","  inflating: cloudml-samples-master/testing/ubuntu/release/census.cfg  \n","  inflating: cloudml-samples-master/testing/ubuntu/release/common.cfg  \n","  inflating: cloudml-samples-master/testing/ubuntu/release/flowers.cfg  \n","  inflating: cloudml-samples-master/testing/ubuntu/setup_and_run_test.sh  \n","   creating: cloudml-samples-master/tools/\n","  inflating: cloudml-samples-master/tools/check_environment.py  \n","  inflating: cloudml-samples-master/tools/setup_cloud_shell.sh  \n","  inflating: cloudml-samples-master/tools/setup_docker.sh  \n","   creating: cloudml-samples-master/tpu/\n","  inflating: cloudml-samples-master/tpu/README.md  \n","   creating: cloudml-samples-master/xgboost/\n","   creating: cloudml-samples-master/xgboost/notebooks/\n","  inflating: cloudml-samples-master/xgboost/notebooks/Online Prediction with XGBoost.ipynb  \n"],"name":"stdout"}]},{"metadata":{"id":"1Vo8zelzKXM-","colab_type":"text"},"cell_type":"markdown","source":["## Develop and validate your trainer locally\n","\n","Before you run your trainer in the cloud, get it running locally. Local environments provide an efficient development and validation workflow so that you can iterate quickly. You also won't incur charges for cloud resources when debugging your application."]},{"metadata":{"id":"KRc7sr9KKimd","colab_type":"text"},"cell_type":"markdown","source":["### Get your training data\n","\n","The relevant data files, adult.data and adult.test, are hosted in a public Google Cloud Storage bucket. For purposes of this sample, use the versions on Cloud Storage, which have undergone some trivial cleaning, instead of the original source data. See [About the data](https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction?authuser=0&hl=ko#about-data) for more information.\n","\n","1.Download the data to a local file directory and set variables that point to the downloaded data files."]},{"metadata":{"id":"oF4jSuerKPp-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":103},"outputId":"a02a7a90-30c5-4186-b471-da574da97733","executionInfo":{"status":"ok","timestamp":1525408031889,"user_tz":-540,"elapsed":4672,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!mkdir data\n","!gsutil -m cp gs://cloudml-public/census/data/* data/"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Copying gs://cloudml-public/census/data/adult.data.csv...\r\n","Copying gs://cloudml-public/census/data/adult.test.csv...\n","/ [2/2 files][  5.7 MiB/  5.7 MiB] 100% Done                                    \n","Operation completed over 2 objects/5.7 MiB.                                      \n"],"name":"stdout"}]},{"metadata":{"id":"cQCHK1NbK4Qa","colab_type":"text"},"cell_type":"markdown","source":["2.Set the TRAIN_DATA AND EVAL_DATA variables to your local file paths. For example, the following commands set the variables to local paths."]},{"metadata":{"id":"ohPLHUvvMpkS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","os.environ['TRAIN_DATA'] = \"/content/data/adult.data.csv\"\n","os.environ['EVAL_DATA'] = \"/content/data/adult.test.csv\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xm-L8ilMNE1b","colab_type":"text"},"cell_type":"markdown","source":["The data is stored in comma-separated value format as shown by the following preview of the adult.data file:"]},{"metadata":{"id":"KpPzPJLXLEM5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, Male, 2174, 0, 40, United-States, <=50K\n","50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 13, United-States, <=50K\n","38, Private, 215646, HS-grad, 9, Divorced, Handlers-cleaners, Not-in-family, White, Male, 0, 0, 40, United-States, <=50K\n","53, Private, 234721, 11th, 7, Married-civ-spouse, Handlers-cleaners, Husband, Black, Male, 0, 0, 40, United-States, <=50K\n","..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"I_DtyHd8dsZD","colab_type":"text"},"cell_type":"markdown","source":["### Install dependencies\n","\n","Although TensorFlow is installed on Cloud Shell, you must run the sample's requirements.txt file to ensure you are using the same version of TensorFlow required by the sample.\n","\n","The sample provides a requirements.txt file that you can use to install the dependencies required by the project."]},{"metadata":{"id":"k_7Urt_5d6wD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":467},"outputId":"2555e907-1e82-4931-a796-7666dfc02c6d","executionInfo":{"status":"ok","timestamp":1525408054699,"user_tz":-540,"elapsed":18689,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!pip install -r cloudml-samples-master/census/requirements.txt"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting tensorflow<1.5,>=1.4 (from -r cloudml-samples-master/census/requirements.txt (line 1))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/de/1a8de6c1119cf595a38bedcb6072b5988ee92b0bf33b7b74b81aa7cffc49/tensorflow-1.4.1-cp27-cp27mu-manylinux1_x86_64.whl (40.7MB)\n","\u001b[K    100% |████████████████████████████████| 40.8MB 853kB/s \n","\u001b[?25hCollecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/cd/f3d14d441eb1c5228aaf7e12e8e94895ae73e9af50383e481610b34357bd/tensorflow_tensorboard-0.4.0-py2-none-any.whl (1.7MB)\n","\u001b[K    100% |████████████████████████████████| 1.7MB 16.4MB/s \n","\u001b[?25hRequirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (1.1.6)\n","Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (3.5.2.post1)\n","Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (0.31.0)\n","Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (1.0.post1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (1.11.0)\n","Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (1.14.3)\n","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (1.5.0)\n","Requirement already satisfied: futures>=3.1.1; python_version < \"3.2\" in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (3.2.0)\n","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (0.9999999)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (0.14.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (2.6.11)\n","Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (1.0.2)\n","Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (4.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.3.0->tensorflow<1.5,>=1.4->-r cloudml-samples-master/census/requirements.txt (line 1)) (39.1.0)\n","Installing collected packages: tensorflow-tensorboard, tensorflow\n","  Found existing installation: tensorflow 1.7.0\n","    Uninstalling tensorflow-1.7.0:\n","      Successfully uninstalled tensorflow-1.7.0\n","Successfully installed tensorflow-1.4.1 tensorflow-tensorboard-0.4.0\n"],"name":"stdout"}]},{"metadata":{"id":"OuVFdsbJewk7","colab_type":"text"},"cell_type":"markdown","source":["Running this command will install TensorFlow 1.4, which is used in the tutorial."]},{"metadata":{"id":"Thv0F8mPezlj","colab_type":"text"},"cell_type":"markdown","source":["### Run a local trainer\n","\n","A local trainer loads your Python training program and starts a training process in an environment that's similar to that of a live Cloud ML Engine cloud training job.\n","\n","1.Specify an output directory and set a MODEL_DIR variable. The following command sets MODEL_DIR to a value of output."]},{"metadata":{"id":"g-CDpYI9eaS9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['MODEL_DIR'] = \"/content/cloudml-samples-master/census/estimator/output\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SoftD1nXfCuB","colab_type":"text"},"cell_type":"markdown","source":["2.It's a good practice to delete the contents of the output directory in case data remains from a previous training run. The following command deletes all data in the output directory."]},{"metadata":{"id":"74b2PvxAeelu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#rm -rf $MODEL_DIR/*"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7YCsFZG0fQx8","colab_type":"text"},"cell_type":"markdown","source":["3.To run your training locally, run the following command:"]},{"metadata":{"id":"gTevG9zHqXXW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!find / -name \"census-eval\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"_uhXEyDykS4C","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":219},"outputId":"eaeeec51-1bb3-4288-af10-0287889b0a8b","executionInfo":{"status":"ok","timestamp":1525412325277,"user_tz":-540,"elapsed":1976,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!ls -al /content/cloudml-samples-master/census/estimator/output-dist"],"execution_count":85,"outputs":[{"output_type":"stream","text":["total 18440\r\n","drwxr-xr-x 3 root root     4096 May  4 05:24 .\r\n","drwxr-xr-x 5 root root     4096 May  4 05:24 ..\r\n","-rw-r--r-- 1 root root       81 May  4 05:24 checkpoint\r\n","drwxr-xr-x 2 root root     4096 May  4 05:24 eval_census-eval\r\n","-rw-r--r-- 1 root root  3449524 May  4 05:24 events.out.tfevents.1525411443.1e4d2f47152d\r\n","-rw-r--r-- 1 root root  2050401 May  4 05:24 graph.pbtxt\r\n","-rw-r--r-- 1 root root 12248600 May  4 05:24 model.ckpt-0.data-00000-of-00002\r\n","-rw-r--r-- 1 root root   158264 May  4 05:24 model.ckpt-0.data-00001-of-00002\r\n","-rw-r--r-- 1 root root     2493 May  4 05:24 model.ckpt-0.index\r\n","-rw-r--r-- 1 root root   944692 May  4 05:24 model.ckpt-0.meta\r\n"],"name":"stdout"}]},{"metadata":{"id":"SOyvoTGsqxMZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":368},"outputId":"5d38bb3f-6b2d-40d4-8a16-26004ad1e785","executionInfo":{"status":"ok","timestamp":1525412481212,"user_tz":-540,"elapsed":2419,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud compute ml-engine --help"],"execution_count":87,"outputs":[{"output_type":"stream","text":["\u001b[1;31mERROR:\u001b[0m (gcloud.compute) Invalid choice: 'ml-engine'.\r\n","Usage: gcloud compute [optional flags] <group | command>\r\n","  group may be           accelerator-types | addresses | backend-buckets |\r\n","                         backend-services | commitments | disk-types | disks |\r\n","                         firewall-rules | forwarding-rules | health-checks |\r\n","                         http-health-checks | https-health-checks | images |\r\n","                         instance-groups | instance-templates | instances |\r\n","                         interconnects | machine-types | networks | operations |\r\n","                         os-login | project-info | regions | routers | routes |\r\n","                         shared-vpc | snapshots | ssl-certificates |\r\n","                         ssl-policies | target-http-proxies |\r\n","                         target-https-proxies | target-instances |\r\n","                         target-pools | target-ssl-proxies |\r\n","                         target-tcp-proxies | target-vpn-gateways | url-maps |\r\n","                         vpn-tunnels | xpn | zones\r\n","  command may be         config-ssh | connect-to-serial-port | copy-files |\r\n","                         reset-windows-password | scp | ssh\r\n","\r\n","For detailed information on this command and its flags, run:\r\n","  gcloud compute --help\r\n"],"name":"stdout"}]},{"metadata":{"id":"h7mh83YnfKh2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":616},"outputId":"499f54aa-89f9-4d4a-a21c-333f01a88d8a","executionInfo":{"status":"ok","timestamp":1525411291990,"user_tz":-540,"elapsed":17067,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine local train \\\n","    --module-name trainer.task \\\n","    --package-path cloudml-samples-master/census/estimator/trainer/ \\\n","    --job-dir $MODEL_DIR \\\n","    -- \\\n","    --train-files $TRAIN_DATA \\\n","    --eval-files $EVAL_DATA \\\n","    --train-steps 1000 \\\n","    --eval-steps 100"],"execution_count":63,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n","  from ._conv import register_converters as _register_converters\n","INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {}, u'job': {u'args': [u'--train-files', u'gs://cpb100-182208/data/adult.data.csv', u'--eval-files', u'gs://cpb100-182208/data/adult.test.csv', u'--train-steps', u'1000', u'--eval-steps', u'100', u'--job-dir', u'/content/cloudml-samples-master/census/estimator/output'], u'job_name': u'trainer.task'}, u'task': {}}\n","model dir /content/cloudml-samples-master/census/estimator/output\n","INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f63fd07cb50>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/cloudml-samples-master/census/estimator/output', '_save_summary_steps': 100}\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/cloudml-samples-master/census/estimator/output/model.ckpt.\n","INFO:tensorflow:Loss for final step: None.\n","WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n","WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n","INFO:tensorflow:Starting evaluation at 2018-05-04-05:21:26\n","INFO:tensorflow:Restoring parameters from /content/cloudml-samples-master/census/estimator/output/model.ckpt-0\n","INFO:tensorflow:Finished evaluation at 2018-05-04-05:21:26\n","INFO:tensorflow:Saving dict for global step 0: accuracy = 0.0, accuracy_baseline = 1.0, auc = 0.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 0, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Restoring parameters from /content/cloudml-samples-master/census/estimator/output/model.ckpt-0\n","INFO:tensorflow:Saving checkpoints for 0 into /content/cloudml-samples-master/census/estimator/output/model.ckpt.\n","INFO:tensorflow:Loss for final step: None.\n","WARNING:tensorflow:No new checkpoint ready for evaluation. Skip the current evaluation pass as evaluation results are expected to be same for the same checkpoint.\n","Traceback (most recent call last):\n","  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n","    \"__main__\", fname, loader, pkg_name)\n","  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n","    exec code in run_globals\n","  File \"/content/cloudml-samples-master/census/estimator/trainer/task.py\", line 170, in <module>\n","    run_experiment(hparams)\n","  File \"/content/cloudml-samples-master/census/estimator/trainer/task.py\", line 56, in run_experiment\n","    eval_spec)\n","  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 432, in train_and_evaluate\n","    executor.run_local()\n","  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 622, in run_local\n","    raise RuntimeError('There was no new checkpoint after the training.')\n","RuntimeError: There was no new checkpoint after the training.\n"],"name":"stdout"}]},{"metadata":{"id":"WeUzBTy1hSa9","colab_type":"text"},"cell_type":"markdown","source":["By default, verbose logging is turned off. You can enable it by setting the --verbosity tag to DEBUG. You'll enable it in a later example command."]},{"metadata":{"id":"T4jjDVCLhYBq","colab_type":"text"},"cell_type":"markdown","source":["### Inspect the summary logs using Tensorboard"]},{"metadata":{"id":"bp1gv1rOhZls","colab_type":"text"},"cell_type":"markdown","source":["To see the evaluation results, you can use the vizualization tool called [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard?authuser=0&hl=ko). With TensorBoard, you can visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through the graph. Tensorboard is available as part of the TensorFlow installation.\n","\n","Follow the steps below to launch TensorBoard and point it at the summary logs produced during training, both during and after execution."]},{"metadata":{"id":"P9G97KA5fTxQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"30f534d0-9f40-4773-fce6-a3e82f7529c9","executionInfo":{"status":"ok","timestamp":1525343843764,"user_tz":-540,"elapsed":1833,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["LOG_DIR = \"/content/cloudml-samples-master/census/estimator/output\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","# https://blog.outsider.ne.kr/1159 ngrok으로 로컬 네트워크의 터널 열기\n","# ! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","# ! unzip ngrok-stable-linux-amd64.zip\n","get_ipython().system_raw('./ngrok http 6006 &')\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":34,"outputs":[{"output_type":"stream","text":["http://a48ea160.ngrok.io\r\n"],"name":"stdout"}]},{"metadata":{"id":"Q9cGzjBzmfyz","colab_type":"text"},"cell_type":"markdown","source":["![check_tensorboard](https://cloud.google.com/ml-engine/docs/images/tensorboard-accuracy.png?hl=ko)"]},{"metadata":{"id":"Mk0N6Cu3lOVS","colab_type":"text"},"cell_type":"markdown","source":["You can shut down TensorBoard at any time by typing ctrl+c on the command line.\n","\n","#### Run a local trainer in distributed mode\n","\n","You can also test whether your model works with the Cloud ML Engine's distributed execution environment by running a local trainer using the --distributed flag."]},{"metadata":{"id":"Xf-4-e1hlSW1","colab_type":"text"},"cell_type":"markdown","source":["1.Specify an output directory and set MODEL_DIR variable again. The following command sets MODEL_DIR to a value of output-dist."]},{"metadata":{"id":"4uqUPZlGl0mC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['MODEL_DIR']=\"output-dist\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZdhkqKWSmwHj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"d6e97bd2-ca53-4b16-f9f9-a43f0daf3e7e","executionInfo":{"status":"ok","timestamp":1525411480148,"user_tz":-540,"elapsed":1802,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!ls /content/cloudml-samples-master/census/estimator"],"execution_count":69,"outputs":[{"output_type":"stream","text":["output\toutput-dist  trainer\r\n"],"name":"stdout"}]},{"metadata":{"id":"yX8u4eRkl3Of","colab_type":"text"},"cell_type":"markdown","source":["2.Remember to delete the contents of the output directory in case data remains from a previous training run. The following command deletes all data in the output directory."]},{"metadata":{"id":"a06bJSGwi1or","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#!rm -rf $MODEL_DIR"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AnI5Z9J_mXAW","colab_type":"text"},"cell_type":"markdown","source":["3.Run the local train command using the --distributed option. Be sure to place the flag above the -- that separates the user arguments from the command-line arguments."]},{"metadata":{"id":"W7h9ajGygWKZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":863},"outputId":"ada7c5cd-8d89-4896-f04b-b328d434e209","executionInfo":{"status":"ok","timestamp":1525411453212,"user_tz":-540,"elapsed":18243,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine local train \\\n","    --module-name trainer.task \\\n","    --package-path cloudml-samples-master/census/estimator/trainer/ \\\n","    --job-dir $MODEL_DIR \\\n","    --distributed \\\n","    -- \\\n","    --train-files $TRAIN_DATA \\\n","    --eval-files $EVAL_DATA \\\n","    --train-steps 1000 \\\n","    --eval-steps 100"],"execution_count":68,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n","  from ._conv import register_converters as _register_converters\r\n","/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n","  from ._conv import register_converters as _register_converters\r\n","/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n","  from ._conv import register_converters as _register_converters\n","/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n","/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n","INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'localhost:27183', u'localhost:27184'], u'worker': [u'localhost:27185', u'localhost:27186'], u'master': [u'localhost:27182']}, u'job': {u'args': [u'--train-files', u'gs://cpb100-182208/data/adult.data.csv', u'--eval-files', u'gs://cpb100-182208/data/adult.test.csv', u'--train-steps', u'1000', u'--eval-steps', u'100', u'--job-dir', u'output-dist'], u'job_name': u'trainer.task'}, u'task': {u'index': 0, u'type': u'ps'}}\n","model dir output-dist\n","INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'ps', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f71a20888d0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_master': u'grpc://localhost:27183', '_num_worker_replicas': 3, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'output-dist', '_save_summary_steps': 100}\n","INFO:tensorflow:Start Tensorflow server.\n","E0504 05:24:01.532654138    3299 ev_epoll1_linux.c:1051]     grpc epoll fd: 4\n","INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'localhost:27183', u'localhost:27184'], u'worker': [u'localhost:27185', u'localhost:27186'], u'master': [u'localhost:27182']}, u'job': {u'args': [u'--train-files', u'gs://cpb100-182208/data/adult.data.csv', u'--eval-files', u'gs://cpb100-182208/data/adult.test.csv', u'--train-steps', u'1000', u'--eval-steps', u'100', u'--job-dir', u'output-dist'], u'job_name': u'trainer.task'}, u'task': {u'index': 0, u'type': u'worker'}}\n","model dir output-dist\n","INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'worker', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd433ec88d0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_master': u'grpc://localhost:27185', '_num_worker_replicas': 3, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'output-dist', '_save_summary_steps': 100}\n","INFO:tensorflow:Start Tensorflow server.\n","E0504 05:24:01.616091450    3295 ev_epoll1_linux.c:1051]     grpc epoll fd: 4\n","INFO:tensorflow:Waiting 5 secs before starting training.\n","INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'localhost:27183', u'localhost:27184'], u'worker': [u'localhost:27185', u'localhost:27186'], u'master': [u'localhost:27182']}, u'job': {u'args': [u'--train-files', u'gs://cpb100-182208/data/adult.data.csv', u'--eval-files', u'gs://cpb100-182208/data/adult.test.csv', u'--train-steps', u'1000', u'--eval-steps', u'100', u'--job-dir', u'output-dist'], u'job_name': u'trainer.task'}, u'task': {u'index': 1, u'type': u'ps'}}\n","model dir output-dist\n","INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'ps', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe7bd0ce8d0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_master': u'grpc://localhost:27184', '_num_worker_replicas': 3, '_task_id': 1, '_log_step_count_steps': 100, '_model_dir': 'output-dist', '_save_summary_steps': 100}\n","INFO:tensorflow:Start Tensorflow server.\n","E0504 05:24:01.677068367    3302 ev_epoll1_linux.c:1051]     grpc epoll fd: 4\n","INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'localhost:27183', u'localhost:27184'], u'worker': [u'localhost:27185', u'localhost:27186'], u'master': [u'localhost:27182']}, u'job': {u'args': [u'--train-files', u'gs://cpb100-182208/data/adult.data.csv', u'--eval-files', u'gs://cpb100-182208/data/adult.test.csv', u'--train-steps', u'1000', u'--eval-steps', u'100', u'--job-dir', u'output-dist'], u'job_name': u'trainer.task'}, u'task': {u'index': 0, u'type': u'master'}}\n","model dir output-dist\n","INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'master', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5d7461d210>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_master': u'grpc://localhost:27182', '_num_worker_replicas': 3, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'output-dist', '_save_summary_steps': 100}\n","INFO:tensorflow:Start Tensorflow server.\n","E0504 05:24:01.776757290    3306 ev_epoll1_linux.c:1051]     grpc epoll fd: 4\n","INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'localhost:27183', u'localhost:27184'], u'worker': [u'localhost:27185', u'localhost:27186'], u'master': [u'localhost:27182']}, u'job': {u'args': [u'--train-files', u'gs://cpb100-182208/data/adult.data.csv', u'--eval-files', u'gs://cpb100-182208/data/adult.test.csv', u'--train-steps', u'1000', u'--eval-steps', u'100', u'--job-dir', u'output-dist'], u'job_name': u'trainer.task'}, u'task': {u'index': 1, u'type': u'worker'}}\n","model dir output-dist\n","INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'worker', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe2c4a3b8d0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_master': u'grpc://localhost:27186', '_num_worker_replicas': 3, '_task_id': 1, '_log_step_count_steps': 100, '_model_dir': 'output-dist', '_save_summary_steps': 100}\n","INFO:tensorflow:Start Tensorflow server.\n","E0504 05:24:01.799816416    3296 ev_epoll1_linux.c:1051]     grpc epoll fd: 4\n","INFO:tensorflow:Waiting 10 secs before starting training.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Saving checkpoints for 0 into output-dist/model.ckpt.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n","WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n","INFO:tensorflow:Starting evaluation at 2018-05-04-05:24:10\n","INFO:tensorflow:Restoring parameters from output-dist/model.ckpt-0\n","INFO:tensorflow:Finished evaluation at 2018-05-04-05:24:11\n","INFO:tensorflow:Saving dict for global step 0: accuracy = 0.0, accuracy_baseline = 1.0, auc = 0.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 0, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n","INFO:tensorflow:Loss for final step: None.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: None.\r\n","INFO:tensorflow:Training has already ended. But the last eval is skipped due to eval throttle_secs. Now evaluating the final checkpoint.\r\n","WARNING:tensorflow:No new checkpoint ready for evaluation. Skip the current evaluation pass as evaluation results are expected to be same for the same checkpoint.\r\n"],"name":"stdout"}]},{"metadata":{"id":"TYMLWXvBmpNI","colab_type":"text"},"cell_type":"markdown","source":["### Inspect the output\n","\n","Output files are written to the directory specified by --job-dir, which was set to output-dist:"]},{"metadata":{"id":"QdsyJ5n2m8Sq","colab_type":"text"},"cell_type":"markdown","source":["You should see output similar to:"]},{"metadata":{"id":"D-pYfeD9glyI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":170},"outputId":"5503d930-3940-4aef-8aef-06ce270d6374","executionInfo":{"status":"ok","timestamp":1525411525112,"user_tz":-540,"elapsed":1954,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!ls -R /content/cloudml-samples-master/census/estimator/output-dist"],"execution_count":72,"outputs":[{"output_type":"stream","text":["/content/cloudml-samples-master/census/estimator/output-dist:\r\n","checkpoint\t\t\t\t     model.ckpt-0.data-00000-of-00002\r\n","eval_census-eval\t\t\t     model.ckpt-0.data-00001-of-00002\r\n","events.out.tfevents.1525411443.1e4d2f47152d  model.ckpt-0.index\r\n","graph.pbtxt\t\t\t\t     model.ckpt-0.meta\r\n","\r\n","/content/cloudml-samples-master/census/estimator/output-dist/eval_census-eval:\r\n","events.out.tfevents.1525411451.1e4d2f47152d\r\n"],"name":"stdout"}]},{"metadata":{"id":"YkUrDp_UnC-U","colab_type":"text"},"cell_type":"markdown","source":["### Inspect the logs\n","\n","Inspect the summary logs using Tensorboard the same way that you did for the single-instance training job except that you change the --logdir value to match the output directory name you used for distributed mode."]},{"metadata":{"id":"r87K509ygqkW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["LOG_DIR = \"/content/cloudml-samples-master/census/estimator/output\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","# https://blog.outsider.ne.kr/1159 ngrok으로 로컬 네트워크의 터널 열기\n","# ! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","# ! unzip ngrok-stable-linux-amd64.zip\n","get_ipython().system_raw('./ngrok http 6006 &')\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3FpbEJYXn4vs","colab_type":"text"},"cell_type":"markdown","source":["## Set up your Cloud Storage bucket\n","\n","This section shows you how to create a new bucket. You can use an existing bucket, but if it is not part of the project you are using to run Cloud ML Engine, you must explicitly [grant access to the Cloud ML Engine service accounts](https://cloud.google.com/ml-engine/docs/working-with-cloud-storage?authuser=0&hl=ko).\n","\n","Create a [Cloud Storage](https://cloud.google.com/storage?authuser=0&hl=ko) bucket for reading and writing data during model training and batch prediction:"]},{"metadata":{"id":"N0K0dj3FqZ6y","colab_type":"text"},"cell_type":"markdown","source":["1.Specify a name for your new bucket. The name must be unique across all buckets in Cloud Storage."]},{"metadata":{"id":"ZiUAH-wcrkDw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['BUCKET_NAME'] =\"gpu-test-cifar10\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"-Vw-njucqcJn","colab_type":"text"},"cell_type":"markdown","source":["For example, use your project name with -mlengine appended:"]},{"metadata":{"id":"d1a6xz1vqddn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['PROJECT_ID']=\"cpb100-182208\"\n","# os.environ['BUCKET_NAME']=os.environ['PROJECT_ID']+\"-mlengine\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"sbO9aLenqe7g","colab_type":"text"},"cell_type":"markdown","source":["2.Check the bucket name that you created."]},{"metadata":{"id":"r6lc4b-Wqgff","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"4dc6d527-da84-442a-e27b-572069f5aa0e","executionInfo":{"status":"ok","timestamp":1525408241773,"user_tz":-540,"elapsed":1844,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!echo $BUCKET_NAME"],"execution_count":18,"outputs":[{"output_type":"stream","text":["gpu-test-cifar10\r\n"],"name":"stdout"}]},{"metadata":{"id":"2mCPmJDyqiG5","colab_type":"text"},"cell_type":"markdown","source":["3.Select a region for your bucket and set a `REGION` environment variable.\n","\n","Warning: You must specify a region (like us-central1) for your bucket, not a multi-region location (like us). See the [available regions](https://cloud.google.com/ml-engine/docs/regions?authuser=0&hl=ko) for Cloud ML Engine services. For example, the following code creates `REGION` and sets it to `us-central1`."]},{"metadata":{"id":"IoHou2CAqnAX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['REGION']=\"us-east1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"7xoXBx3dqoh-","colab_type":"text"},"cell_type":"markdown","source":["4.Create the new bucket:"]},{"metadata":{"id":"GPLnSErUqqCW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["gsutil mb -l $REGION gs://$BUCKET_NAME"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lLhdsBgJqrWG","colab_type":"text"},"cell_type":"markdown","source":["Note: Use the same region where you plan on running Cloud ML Engine jobs. The example uses us-central1 because that is the region used in the quickstart instructions.\n","\n","Next, upload the data files to your Cloud Storage bucket.\n","\n","1.Use gsutil to copy the two files to your Cloud Storage bucket."]},{"metadata":{"id":"m4y-2BwZqwFZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":103},"outputId":"fde66754-7081-48f1-c546-93247eb6fb05","executionInfo":{"status":"ok","timestamp":1525345656049,"user_tz":-540,"elapsed":5255,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gsutil cp -r data gs://$BUCKET_NAME/data"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Copying file://data/adult.data.csv [Content-Type=text/csv]...\n","Copying file://data/adult.test.csv [Content-Type=text/csv]...\n","- [2 files][  5.7 MiB/  5.7 MiB]                                                \n","Operation completed over 2 objects/5.7 MiB.                                      \n"],"name":"stdout"}]},{"metadata":{"id":"s6Yw7MGSrY7e","colab_type":"text"},"cell_type":"markdown","source":["2.Set the TRAIN_DATA and EVAL_DATA variables to point to the files."]},{"metadata":{"id":"7iJ1j4kJrZiQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['TRAIN_DATA']=\"gs://cpb100-182208/data/adult.data.csv\"\n","os.environ['EVAL_DATA']=\"gs://cpb100-182208/data/adult.test.csv\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"coRiAqOguGqq","colab_type":"text"},"cell_type":"markdown","source":["3.Use gsutil again to copy the JSON test file test.json to your Cloud Storage bucket."]},{"metadata":{"id":"UNlbE-K9sAUe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":87},"outputId":"d11b5515-a416-45ca-b029-c48f3e32be4d","executionInfo":{"status":"ok","timestamp":1525346350328,"user_tz":-540,"elapsed":3122,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gsutil cp cloudml-samples-master/census/test.json gs://$BUCKET_NAME/data/test.json"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Copying file://cloudml-samples-master/census/test.json [Content-Type=application/json]...\n","\n","Operation completed over 1 objects/314.0 B.                                      \n"],"name":"stdout"}]},{"metadata":{"id":"GL9ox1nPul_Q","colab_type":"text"},"cell_type":"markdown","source":["4.Set the TEST_JSON variable to point to that file."]},{"metadata":{"id":"yWKelNbxuMdM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['TEST_JSON']=\"gs://cpb100-182208/data/test.json\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"isXhTlFBut3l","colab_type":"text"},"cell_type":"markdown","source":["## Run a single-instance trainer in the cloud"]},{"metadata":{"id":"TfFHnhyMuw-Q","colab_type":"text"},"cell_type":"markdown","source":["With a validated trainer that runs in both single-instance and distributed mode, you're now ready to run a trainer in the cloud. You'll start by requesting a single-instance training job.\n","\n","Use the default BASIC [scale tier](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs?authuser=0&hl=ko#scaletier) to run a single-instance trainer. The initial job request can take a few minutes to start, but subsequent jobs run more quickly. This enables quick iteration as you develop and validate your training job."]},{"metadata":{"id":"oV8oQuCtu1re","colab_type":"text"},"cell_type":"markdown","source":["1.Select a name for the initial training run that distinguishes it from any subsequent training runs. For example, you can append a number to represent the iteration."]},{"metadata":{"id":"zY6Fpga-urWU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['JOB_NAME']=\"census_single_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"h8tzFXiLu7nO","colab_type":"text"},"cell_type":"markdown","source":["2.Specify a directory for output generated by Cloud ML Engine by setting an OUTPUT_PATH variable to include when requesting training and prediction jobs. The OUTPUT_PATH represents the fully qualified Cloud Storage location for model checkpoints, summaries, and exports. You can use the BUCKET_NAME variable you defined in a previous step.\n","\n","It's a good practice to use the job name as the output directory. For example, the following OUTPUT_PATH points to a directory named census-single-1."]},{"metadata":{"id":"YvH-p6pWu5gI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['OUTPUT_PATH']=\"gs://cpb100-182208/census_single_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"iEELkRdHvJy0","colab_type":"text"},"cell_type":"markdown","source":["3.Run the following command to submit a training job in the cloud that uses a single process. This time, set the --verbosity tag to DEBUG so that you can inspect the full logging output and retrieve accuracy, loss, and other metrics. The output also contains a number of other warning messages that you can ignore for the purposes of this sample."]},{"metadata":{"id":"IpuYPPZqvICY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":203},"outputId":"5dc3d96b-062c-4a12-a7da-dd4a814dba68","executionInfo":{"status":"ok","timestamp":1525346991076,"user_tz":-540,"elapsed":5514,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine jobs submit training $JOB_NAME \\\n","    --job-dir $OUTPUT_PATH \\\n","    --runtime-version 1.4 \\\n","    --module-name trainer.task \\\n","    --package-path cloudml-samples-master/census/estimator/trainer/ \\\n","    --region $REGION \\\n","    -- \\\n","    --train-files $TRAIN_DATA \\\n","    --eval-files $EVAL_DATA \\\n","    --train-steps 1000 \\\n","    --eval-steps 100 \\\n","    --verbosity DEBUG"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Job [census_single_1] submitted successfully.\r\n","Your job is still active. You may view the status of your job with the command\r\n","\r\n","  $ gcloud ml-engine jobs describe census_single_1\r\n","\r\n","or continue streaming the logs with the command\r\n","\r\n","  $ gcloud ml-engine jobs stream-logs census_single_1\r\n","jobId: census_single_1\r\n","state: QUEUED\r\n"],"name":"stdout"}]},{"metadata":{"id":"UJs0js2GvaNH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":2301},"outputId":"8a08bc43-20a0-4659-830b-91afd721ee53","executionInfo":{"status":"ok","timestamp":1525347337153,"user_tz":-540,"elapsed":212439,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine jobs stream-logs census_single_1"],"execution_count":78,"outputs":[{"output_type":"stream","text":["INFO\t2018-05-03 11:29:49 +0000\tservice\t\tValidating job requirements...\r\n","INFO\t2018-05-03 11:29:50 +0000\tservice\t\tJob creation request has been successfully validated.\r\n","INFO\t2018-05-03 11:29:50 +0000\tservice\t\tWaiting for job to be provisioned.\r\n","INFO\t2018-05-03 11:29:50 +0000\tservice\t\tJob census_single_1 is queued.\r\n","INFO\t2018-05-03 11:29:53 +0000\tservice\t\tWaiting for TensorFlow to start.\r\n","INFO\t2018-05-03 11:30:44 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://cpb100-182208/census_single_1/packages/fdfb629767ee43119edb06f7be8fa8e0a274e57ecb12352079ad4fbd2a467f88/trainer-0.0.0.tar.gz\"],  \"python_module\": \"trainer.task\",  \"args\": [\"--train-files\", \"gs://cpb100-182208/data/adult.data.csv\", \"--eval-files\", \"gs://cpb100-182208/data/adult.test.csv\", \"--train-steps\", \"1000\", \"--eval-steps\", \"100\", \"--verbosity\", \"DEBUG\"],  \"region\": \"us-east1\",  \"runtime_version\": \"1.4\",  \"job_dir\": \"gs://cpb100-182208/census_single_1\",  \"run_on_raw_vm\": true}\r\n","INFO\t2018-05-03 11:30:49 +0000\tmaster-replica-0\t\tRunning module trainer.task.\r\n","INFO\t2018-05-03 11:30:49 +0000\tmaster-replica-0\t\tDownloading the package: gs://cpb100-182208/census_single_1/packages/fdfb629767ee43119edb06f7be8fa8e0a274e57ecb12352079ad4fbd2a467f88/trainer-0.0.0.tar.gz\r\n","INFO\t2018-05-03 11:30:49 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://cpb100-182208/census_single_1/packages/fdfb629767ee43119edb06f7be8fa8e0a274e57ecb12352079ad4fbd2a467f88/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\r\n","INFO\t2018-05-03 11:30:53 +0000\tmaster-replica-0\t\tInstalling the package: gs://cpb100-182208/census_single_1/packages/fdfb629767ee43119edb06f7be8fa8e0a274e57ecb12352079ad4fbd2a467f88/trainer-0.0.0.tar.gz\r\n","INFO\t2018-05-03 11:30:53 +0000\tmaster-replica-0\t\tRunning command: pip install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\r\n","INFO\t2018-05-03 11:31:00 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\r\n","INFO\t2018-05-03 11:31:00 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer\r\n","INFO\t2018-05-03 11:31:00 +0000\tmaster-replica-0\t\t  Running setup.py bdist_wheel for trainer: started\r\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tcreating '/tmp/pip-wheel-KnzX1m/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\r\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer/model.py'\r\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer/task.py'\r\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer/__init__.py'\r\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tSuccessfully built trainer\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tInstalling collected packages: trainer\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tSuccessfully installed trainer-0.0.0\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tRunning command: pip install --user trainer-0.0.0.tar.gz\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer\n","INFO\t2018-05-03 11:31:01 +0000\tmaster-replica-0\t\t  Running setup.py bdist_wheel for trainer: started\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tcreating '/tmp/pip-wheel-BO4zSP/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer/model.py'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer/task.py'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer/__init__.py'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n","INFO\t2018-05-03 11:31:02 +0000\tmaster-replica-0\t\tSuccessfully built trainer\n","ERROR\t2018-05-03 11:31:08 +0000\tmaster-replica-0\t\tgapic-google-cloud-logging-v2 0.91.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\n","INFO\t2018-05-03 11:31:08 +0000\tmaster-replica-0\t\tInstalling collected packages: trainer\n","INFO\t2018-05-03 11:31:08 +0000\tmaster-replica-0\t\t  Found existing installation: trainer 0.0.0\n","INFO\t2018-05-03 11:31:08 +0000\tmaster-replica-0\t\t    Uninstalling trainer-0.0.0:\n","INFO\t2018-05-03 11:31:08 +0000\tmaster-replica-0\t\t      Successfully uninstalled trainer-0.0.0\n","INFO\t2018-05-03 11:31:08 +0000\tmaster-replica-0\t\tSuccessfully installed trainer-0.0.0\n","INFO\t2018-05-03 11:31:08 +0000\tmaster-replica-0\t\tRunning command: python -m trainer.task --train-files gs://cpb100-182208/data/adult.data.csv --eval-files gs://cpb100-182208/data/adult.test.csv --train-steps 1000 --eval-steps 100 --verbosity DEBUG --job-dir gs://cpb100-182208/census_single_1\n","INFO\t2018-05-03 11:31:12 +0000\tmaster-replica-0\t\tTF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'127.0.0.1:2222']}, u'job': {u'python_module': u'trainer.task', u'region': u'us-east1', u'args': [u'--train-files', u'gs://cpb100-182208/data/adult.data.csv', u'--eval-files', u'gs://cpb100-182208/data/adult.test.csv', u'--train-steps', u'1000', u'--eval-steps', u'100', u'--verbosity', u'DEBUG', u'--job-dir', u'gs://cpb100-182208/census_single_1'], u'job_dir': u'gs://cpb100-182208/census_single_1', u'runtime_version': u'1.4', u'package_uris': [u'gs://cpb100-182208/census_single_1/packages/fdfb629767ee43119edb06f7be8fa8e0a274e57ecb12352079ad4fbd2a467f88/trainer-0.0.0.tar.gz'], u'run_on_raw_vm': True}, u'task': {u'index': 0, u'type': u'master', u'cloud': u'paa0394cdd43adaf4-ml'}}\n","INFO\t2018-05-03 11:31:12 +0000\tmaster-replica-0\t\tUsing config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'master', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff7ea551fd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'gs://cpb100-182208/census_single_1', '_save_summary_steps': 100}\n","INFO\t2018-05-03 11:31:12 +0000\tmaster-replica-0\t\tSkip starting Tensorflow server as there is only one node in the cluster.\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Female', ' Male'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Female', ' Male'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Never-married', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Never-married', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='occupation', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Husband', ' Not-in-family', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Husband', ' Not-in-family', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' Self-emp-not-inc', ' Private', ' State-gov', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' Self-emp-not-inc', ' Private', ' State-gov', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'occupation'), hash_bucket_size=1000000, hash_key=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=10000, hash_key=None).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Female', ' Male'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:13 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Never-married', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:14 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:14 +0000\tmaster-replica-0\t\tTransforming feature_column _CrossedColumn(keys=('native_country', 'occupation'), hash_bucket_size=10000, hash_key=None).\n","DEBUG\t2018-05-03 11:31:14 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='occupation', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:14 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Husband', ' Not-in-family', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:14 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' Self-emp-not-inc', ' Private', ' State-gov', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","INFO\t2018-05-03 11:31:14 +0000\tmaster-replica-0\t\tCreate CheckpointSaverHook.\n","WARNING\t2018-05-03 11:31:20 +0000\tmaster-replica-0\t\tOut of range: Attempted to repeat an empty dataset infinitely.\n","INFO\t2018-05-03 11:31:20 +0000\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://cpb100-182208/census_single_1/model.ckpt.\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Female', ' Male'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Female', ' Male'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Never-married', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Never-married', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='occupation', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Husband', ' Not-in-family', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Husband', ' Not-in-family', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' Self-emp-not-inc', ' Private', ' State-gov', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0)).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' Self-emp-not-inc', ' Private', ' State-gov', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'occupation'), hash_bucket_size=1000000, hash_key=None).\n","DEBUG\t2018-05-03 11:31:31 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='race', vocabulary_list=(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=10000, hash_key=None).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Female', ' Male'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Never-married', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _CrossedColumn(keys=('native_country', 'occupation'), hash_bucket_size=10000, hash_key=None).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _HashedCategoricalColumn(key='occupation', hash_bucket_size=100, dtype=tf.string).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Husband', ' Not-in-family', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","DEBUG\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tTransforming feature_column _VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' Self-emp-not-inc', ' Private', ' State-gov', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0).\n","WARNING\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tCasting <dtype: 'float32'> labels to bool.\n","WARNING\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tCasting <dtype: 'float32'> labels to bool.\n","INFO\t2018-05-03 11:31:32 +0000\tmaster-replica-0\t\tStarting evaluation at 2018-05-03-11:31:32\n","INFO\t2018-05-03 11:31:33 +0000\tmaster-replica-0\t\tRestoring parameters from gs://cpb100-182208/census_single_1/model.ckpt-0\n","WARNING\t2018-05-03 11:31:35 +0000\tmaster-replica-0\t\tOut of range: Attempted to repeat an empty dataset infinitely.\n","INFO\t2018-05-03 11:31:35 +0000\tmaster-replica-0\t\tFinished evaluation at 2018-05-03-11:31:35\n","INFO\t2018-05-03 11:31:35 +0000\tmaster-replica-0\t\tSaving dict for global step 0: accuracy = 0.0, accuracy_baseline = 1.0, auc = 0.0, auc_precision_recall = 0.0, average_loss = 0.0, global_step = 0, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n","INFO\t2018-05-03 11:31:38 +0000\tmaster-replica-0\t\tLoss for final step: None.\n","INFO\t2018-05-03 11:31:38 +0000\tmaster-replica-0\t\tTraining has already ended. But the last eval is skipped due to eval throttle_secs. Now evaluating the final checkpoint.\n","WARNING\t2018-05-03 11:31:39 +0000\tmaster-replica-0\t\tNo new checkpoint ready for evaluation. Skip the current evaluation pass as evaluation results are expected to be same for the same checkpoint.\n","INFO\t2018-05-03 11:31:39 +0000\tmaster-replica-0\t\tmodel dir gs://cpb100-182208/census_single_1\n","INFO\t2018-05-03 11:31:39 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n","INFO\t2018-05-03 11:31:39 +0000\tmaster-replica-0\t\tClean up finished.\n","INFO\t2018-05-03 11:31:39 +0000\tmaster-replica-0\t\tTask completed successfully.\n"],"name":"stdout"}]},{"metadata":{"id":"sKe6yXmfx_we","colab_type":"text"},"cell_type":"markdown","source":["You can monitor the progress of your trainer by watching the command-line output or in ML Engine > Jobs on [Google Cloud Platform Console](https://console.cloud.google.com/ml/jobs?authuser=0&hl=ko&_ga=2.199009711.-1080636544.1524192810)."]},{"metadata":{"id":"9iDmkZGhyE94","colab_type":"text"},"cell_type":"markdown","source":["See how to [submit a training job using Python 3.5](https://cloud.google.com/ml-engine/docs/tensorflow/versioning?authuser=0&hl=ko#set-python-version-training)."]},{"metadata":{"id":"2Dw1mmILy30C","colab_type":"text"},"cell_type":"markdown","source":["#### Inspect the output"]},{"metadata":{"id":"SJIWXn_zy6EJ","colab_type":"text"},"cell_type":"markdown","source":["In cloud training, outputs are produced into Google Cloud Storage. In this sample, outputs are saved to OUTPUT_PATH; to list them, run:"]},{"metadata":{"id":"AchvWPxyvv7L","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":318},"outputId":"37c72a29-f41a-4849-af93-7a80cd6262b5","executionInfo":{"status":"ok","timestamp":1525347516504,"user_tz":-540,"elapsed":3234,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gsutil ls -r $OUTPUT_PATH"],"execution_count":79,"outputs":[{"output_type":"stream","text":["gs://cpb100-182208/census_single_1/:\n","gs://cpb100-182208/census_single_1/\n","gs://cpb100-182208/census_single_1/checkpoint\n","gs://cpb100-182208/census_single_1/events.out.tfevents.1525347075.cmle-training-9162507763244226989\n","gs://cpb100-182208/census_single_1/graph.pbtxt\n","gs://cpb100-182208/census_single_1/model.ckpt-0.data-00000-of-00001\n","gs://cpb100-182208/census_single_1/model.ckpt-0.index\n","gs://cpb100-182208/census_single_1/model.ckpt-0.meta\n","\n","gs://cpb100-182208/census_single_1/eval_census-eval/:\n","gs://cpb100-182208/census_single_1/eval_census-eval/\n","gs://cpb100-182208/census_single_1/eval_census-eval/events.out.tfevents.1525347096.cmle-training-9162507763244226989\n","\n","gs://cpb100-182208/census_single_1/packages/:\n","\n","gs://cpb100-182208/census_single_1/packages/fdfb629767ee43119edb06f7be8fa8e0a274e57ecb12352079ad4fbd2a467f88/:\n","gs://cpb100-182208/census_single_1/packages/fdfb629767ee43119edb06f7be8fa8e0a274e57ecb12352079ad4fbd2a467f88/trainer-0.0.0.tar.gz\n"],"name":"stdout"}]},{"metadata":{"id":"1wmeZWrtzF3H","colab_type":"text"},"cell_type":"markdown","source":["The outputs should be similar to the [outputs from training locally (above)](https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction?authuser=0&hl=ko#inspect-local-output)."]},{"metadata":{"id":"p-fTqcbQzOD0","colab_type":"text"},"cell_type":"markdown","source":["### Inspect the Stackdriver logs\n","\n","Logs are a useful way to understand the behavior of your training code on the cloud. When Cloud ML Engine runs a training job, it captures all stdout and stderr streams and logging statements. These logs are stored in Stackdriver Logging; they are visible both during and after execution.\n","\n","The easiest way to find the logs for your job is to select your job in ML Engine > Jobs on [GCP Console](https://console.cloud.google.com/ml/jobs?authuser=0&hl=ko&_ga=2.258827530.-1080636544.1524192810), and then click \"View logs\".\n","\n","If you leave \"All logs\" selected, you will see all logs from all workers. You can also select a specific task; master-replica-0 will give you an overview of the job's execution from the master's perspective.\n","\n","Because you selected verbose logging, you can inspect the full logging output. Look for the term accuracy in the logs:\n","\n","![gcp_console](https://cloud.google.com/ml-engine/docs/images/ml-engine-console-logs-accuracy.png?authuser=0&hl=ko)"]},{"metadata":{"id":"5X5I5uIVzJ_y","colab_type":"text"},"cell_type":"markdown","source":["If you would like to view these logs in your terminal, you can do so from the command line with:"]},{"metadata":{"id":"gOWHkTRpwApg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gcloud ml-engine jobs stream-logs $JOB_NAME"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ld68qqPuzwd7","colab_type":"text"},"cell_type":"markdown","source":["See all the options for [gcloud ml-engine jobs stream-logs](https://cloud.google.com/ml-engine/docs/tensorflow/sdk/gcloud/reference/ml-engine/jobs/stream-logs?authuser=0&hl=ko)."]},{"metadata":{"id":"oD-QlnRcz06g","colab_type":"text"},"cell_type":"markdown","source":["### Inspect the summary logs using Tensorboard\n","\n","You can inspect the behavior of your training by launching [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard?authuser=0&hl=ko) and pointing it at the summary logs produced during training — both during and after execution.\n","\n","Because the training programs write summaries directly to a Cloud Storage location, Tensorboard can automatically read from them without manual copying of event files."]},{"metadata":{"id":"e8KHtv2N0FgN","colab_type":"text"},"cell_type":"markdown","source":["1.Launch TensorBoard:"]},{"metadata":{"id":"K4EPWgU60DTP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["tensorboard --logdir=$OUTPUT_PATH --port=8080"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3u9PI7t50GM_","colab_type":"text"},"cell_type":"markdown","source":["2.Select \"Preview on port 8080\" from the Web Preview menu at the top of the command line."]},{"metadata":{"id":"xdHQyeyIz7yn","colab_type":"text"},"cell_type":"markdown","source":["Click on Accuracy to see graphical representations of how accuracy changes as your job progresses.\n","\n","You can shut down TensorBoard at any time by typing ctrl+c on the command line"]},{"metadata":{"id":"KFP5Qmsy0J0S","colab_type":"text"},"cell_type":"markdown","source":["## Run distributed training in the cloud"]},{"metadata":{"id":"b1LX5SYh0Lpf","colab_type":"text"},"cell_type":"markdown","source":["To take advantage of Google's scalable infrastructure when running training jobs, configure your trainer to run in distributed mode.\n","\n","No code changes are necessary to run this model as a distributed process in Cloud ML Engine.\n","\n","To run a distributed job, set --scale-tier to any tier above basic. For more information about scale tiers, see [scale tier documentation](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs?authuser=0&hl=ko#scaletier)."]},{"metadata":{"id":"ILSO-l2a0Rs5","colab_type":"text"},"cell_type":"markdown","source":["1.Select a name for your distributed training run that distinguishes it from other training runs. For example, you could use dist to represent distributed and a number to represent the iteration."]},{"metadata":{"id":"ghvxVrrSwdvZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['JOB_NAME']=\"census_dist_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"oAygW_QH0Tgm","colab_type":"text"},"cell_type":"markdown","source":["2.Specify OUTPUT_PATH to include the job name so that you don't inadvertently reuse checkpoints between jobs. You might have to redefine BUCKET_NAME if you've started a new command-line session since you last defined it. For example, the following OUTPUT_PATH points to a directory named census-dist-1."]},{"metadata":{"id":"K0MAt-WG0WPF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['OUTPUT_PATH']=\"gs://cpb100-182208/census_dist_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Sfj2_bd0Xmr","colab_type":"text"},"cell_type":"markdown","source":["Run the following command to submit a training job in the cloud that uses multiple workers. Note that the job can take a few minutes to start.\n","\n","Place [--scale-tier](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs?authuser=0&hl=ko#scaletier) above the -- that separates the user arguments from the command-line arguments. For example, the following command uses a scale tier of STANDARD_1:"]},{"metadata":{"id":"5HyQWM4c0bON","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":203},"outputId":"19f83a8a-8003-4e67-da66-526274aade5e","executionInfo":{"status":"ok","timestamp":1525347982508,"user_tz":-540,"elapsed":4385,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine jobs submit training $JOB_NAME \\\n","    --job-dir $OUTPUT_PATH \\\n","    --runtime-version 1.4 \\\n","    --module-name trainer.task \\\n","    --package-path cloudml-samples-master/census/estimator/trainer/ \\\n","    --region $REGION \\\n","    --scale-tier STANDARD_1 \\\n","    -- \\\n","    --train-files $TRAIN_DATA \\\n","    --eval-files $EVAL_DATA \\\n","    --train-steps 1000 \\\n","    --verbosity DEBUG  \\\n","    --eval-steps 100"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Job [census_dist_1] submitted successfully.\r\n","Your job is still active. You may view the status of your job with the command\r\n","\r\n","  $ gcloud ml-engine jobs describe census_dist_1\r\n","\r\n","or continue streaming the logs with the command\r\n","\r\n","  $ gcloud ml-engine jobs stream-logs census_dist_1\r\n","jobId: census_dist_1\r\n","state: QUEUED\r\n"],"name":"stdout"}]},{"metadata":{"id":"cKqLb-_Ai9Ha","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":219},"outputId":"289a6171-d763-4d20-e321-610c047c362c","executionInfo":{"status":"ok","timestamp":1525410821156,"user_tz":-540,"elapsed":3100,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gsutil ls gs://cpb100-182208/census_dist_1"],"execution_count":55,"outputs":[{"output_type":"stream","text":["gs://cpb100-182208/census_dist_1/\r\n","gs://cpb100-182208/census_dist_1/checkpoint\r\n","gs://cpb100-182208/census_dist_1/events.out.tfevents.1525348176.cmle-training-master-9ea5f6f2f5-0-kpl9m\r\n","gs://cpb100-182208/census_dist_1/graph.pbtxt\r\n","gs://cpb100-182208/census_dist_1/model.ckpt-0.data-00000-of-00003\r\n","gs://cpb100-182208/census_dist_1/model.ckpt-0.data-00001-of-00003\r\n","gs://cpb100-182208/census_dist_1/model.ckpt-0.data-00002-of-00003\r\n","gs://cpb100-182208/census_dist_1/model.ckpt-0.index\r\n","gs://cpb100-182208/census_dist_1/model.ckpt-0.meta\r\n","gs://cpb100-182208/census_dist_1/eval_census-eval/\r\n","gs://cpb100-182208/census_dist_1/packages/\r\n"],"name":"stdout"}]},{"metadata":{"id":"FrlsY6_Ik7ze","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":2664},"outputId":"8a7aba50-4a51-4afb-d24b-95b4859790f2","executionInfo":{"status":"ok","timestamp":1525411007245,"user_tz":-540,"elapsed":3221,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gsutil cat -r 0-2000 gs://cpb100-182208/census_dist_1/graph.pbtxt"],"execution_count":60,"outputs":[{"output_type":"stream","text":["node {\r\n","  name: \"global_step/Initializer/zeros\"\r\n","  op: \"Const\"\r\n","  attr {\r\n","    key: \"_class\"\r\n","    value {\r\n","      list {\r\n","        s: \"loc:@global_step\"\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"_output_shapes\"\r\n","    value {\r\n","      list {\r\n","        shape {\r\n","        }\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"dtype\"\r\n","    value {\r\n","      type: DT_INT64\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"value\"\r\n","    value {\r\n","      tensor {\r\n","        dtype: DT_INT64\r\n","        tensor_shape {\r\n","        }\r\n","        int64_val: 0\r\n","      }\r\n","    }\r\n","  }\r\n","}\r\n","node {\r\n","  name: \"global_step\"\r\n","  op: \"VariableV2\"\r\n","  device: \"/job:ps/task:0\"\r\n","  attr {\r\n","    key: \"_class\"\r\n","    value {\r\n","      list {\r\n","        s: \"loc:@global_step\"\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"_output_shapes\"\r\n","    value {\r\n","      list {\r\n","        shape {\r\n","        }\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"container\"\r\n","    value {\r\n","      s: \"\"\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"dtype\"\r\n","    value {\r\n","      type: DT_INT64\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"shape\"\r\n","    value {\r\n","      shape {\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"shared_name\"\r\n","    value {\r\n","      s: \"\"\r\n","    }\r\n","  }\r\n","}\r\n","node {\r\n","  name: \"global_step/Assign\"\r\n","  op: \"Assign\"\r\n","  input: \"global_step\"\r\n","  input: \"global_step/Initializer/zeros\"\r\n","  device: \"/job:ps/task:0\"\r\n","  attr {\r\n","    key: \"T\"\r\n","    value {\r\n","      type: DT_INT64\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"_class\"\r\n","    value {\r\n","      list {\r\n","        s: \"loc:@global_step\"\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"_output_shapes\"\r\n","    value {\r\n","      list {\r\n","        shape {\r\n","        }\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"use_locking\"\r\n","    value {\r\n","      b: true\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"validate_shape\"\r\n","    value {\r\n","      b: true\r\n","    }\r\n","  }\r\n","}\r\n","node {\r\n","  name: \"global_step/read\"\r\n","  op: \"Identity\"\r\n","  input: \"global_step\"\r\n","  device: \"/job:ps/task:0\"\r\n","  attr {\r\n","    key: \"T\"\r\n","    value {\r\n","      type: DT_INT64\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"_class\"\r\n","    value {\r\n","      list {\r\n","        s: \"loc:@global_step\"\r\n","      }\r\n","    }\r\n","  }\r\n","  attr {\r\n","    key: \"_output_shapes\"\r\n","    value {\r\n","      list {\r\n","        shape {\r\n","        }\r\n","      }\r\n","    }\r\n","  }\r\n","}\r\n","node {\r\n","  name: \"IsVariableInitialized\"\r\n","  o"],"name":"stdout"}]},{"metadata":{"id":"9sUCxkaueuN2","colab_type":"text"},"cell_type":"markdown","source":["#### Inspect the logs\n","\n","Inspect the Stackdriver logs and summary logs the same way that you did for the single-instance training job.\n","\n","For Stackdriver logs: Either select your job in ML Engine > Jobs on GCP Console, and then click View logs or use the following command from your terminal:"]},{"metadata":{"id":"B-oQrlwL0huv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["gcloud ml-engine jobs stream-logs $JOB_NAME"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oqVeEAlGe1G2","colab_type":"text"},"cell_type":"markdown","source":["For TensorBoard:\n","\n","1.Launch TensorBoard:"]},{"metadata":{"id":"AXdx-QJYe3H6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["tensorboard --logdir=$OUTPUT_PATH --port=8080"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DADX1nWJe6qu","colab_type":"text"},"cell_type":"markdown","source":["2.Select \"Preview on port 8080\" from the Web Preview menu at the top of the command line."]},{"metadata":{"id":"FGrYb0nQfDdc","colab_type":"text"},"cell_type":"markdown","source":["## Hyperparameter Tuning\n","\n","Cloud ML Engine offers hyperparameter tuning to help you maximize your model's predictive accuracy. The census sample stores the hyperparameter configuration settings in a YAML file named hptuning_config.yaml and includes the file in the training request using the --config variable.\n","\n","1.Select a new job name and create a variable that references the configuration file."]},{"metadata":{"id":"ki3JmndKfQJd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['HPTUNING_CONFIG']=\"cloudml-samples-master/census/hptuning_config.yaml\"\n","os.environ['JOB_NAME']=\"census_core_hptune_1\"\n","os.environ['TRAIN_DATA']=\"gs://cpb100-182208/data/adult.data.csv\"\n","os.environ['EVAL_DATA']=\"gs://cpb100-182208/data/adult.test.csv\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"s3OobcA4foHp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":401},"outputId":"829b5fdf-e277-44b1-de22-1e143a9d81d3","executionInfo":{"status":"ok","timestamp":1525408214317,"user_tz":-540,"elapsed":1795,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!cat cloudml-samples-master/census/hptuning_config.yaml"],"execution_count":14,"outputs":[{"output_type":"stream","text":["trainingInput:\r\n","  hyperparameters:\r\n","    goal: MAXIMIZE\r\n","    hyperparameterMetricTag: accuracy\r\n","    maxTrials: 4\r\n","    maxParallelTrials: 2\r\n","    params:\r\n","      - parameterName: first-layer-size\r\n","        type: INTEGER\r\n","        minValue: 50\r\n","        maxValue: 500\r\n","        scaleType: UNIT_LINEAR_SCALE\r\n","      - parameterName: num-layers\r\n","        type: INTEGER\r\n","        minValue: 1\r\n","        maxValue: 15\r\n","        scaleType: UNIT_LINEAR_SCALE\r\n","      - parameterName: scale-factor\r\n","        type: DOUBLE\r\n","        minValue: 0.1\r\n","        maxValue: 1.0\r\n","        scaleType: UNIT_REVERSE_LOG_SCALE\r\n"],"name":"stdout"}]},{"metadata":{"id":"kJuKRekBgoKI","colab_type":"text"},"cell_type":"markdown","source":["2.Specify OUTPUT_PATH to include the job name so that you don't inadvertently reuse checkpoints between jobs. You might have to redefine BUCKET_NAME if you've started a new command-line session since you last defined it. For example, the following OUTPUT_PATH points to a directory named census_core_hptune_1."]},{"metadata":{"id":"MrZqkphBgqks","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['OUTPUT_PATH']=\"gs://cpb100-182208/census_core_hptune_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"iGAij6JifPBg","colab_type":"text"},"cell_type":"markdown","source":["3.Run the following command to submit a training job that not only uses multiple workers, but also uses hyperparameter tuning."]},{"metadata":{"id":"UmAqVQ9gaexF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"521259ef-600a-4369-ba6e-86b44655fab0","executionInfo":{"status":"ok","timestamp":1525408204731,"user_tz":-540,"elapsed":1699,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!echo $HPTUNING_CONFIG"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\r\n"],"name":"stdout"}]},{"metadata":{"id":"YAzEJNy3gzRu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":120},"outputId":"80da6eef-42ec-4c76-be46-c4620b0b77fb","executionInfo":{"status":"ok","timestamp":1525409992522,"user_tz":-540,"elapsed":4741,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine jobs submit training $JOB_NAME \\\n","    --stream-logs \\\n","    --job-dir $OUTPUT_PATH \\\n","    --runtime-version 1.4 \\\n","    --config $HPTUNING_CONFIG \\\n","    --module-name trainer.task \\\n","    --package-path cloudml-samples-master/census/estimator/trainer/ \\\n","    --region $REGION \\\n","    --scale-tier STANDARD_1 \\\n","    -- \\\n","    --train-files $TRAIN_DATA \\\n","    --eval-files $EVAL_DATA \\\n","    --train-steps 100 \\\n","    --verbosity DEBUG  \\\n","    --eval-steps 100"],"execution_count":29,"outputs":[{"output_type":"stream","text":["\u001b[1;31mERROR:\u001b[0m (gcloud.ml-engine.jobs.submit.training) Resource in project [cpb100-182208] is the subject of a conflict: Field: job.job_id Error: A job with this id already exists.\r\n","- '@type': type.googleapis.com/google.rpc.BadRequest\r\n","  fieldViolations:\r\n","  - description: A job with this id already exists.\r\n","    field: job.job_id\r\n"],"name":"stdout"}]},{"metadata":{"id":"zTbhpYafiQxN","colab_type":"text"},"cell_type":"markdown","source":["For more information about hyperparameter tuning, see Hyperparameter Tuning Overview.\n","\n","You can submit a training job using Python 3.5 by specifying a Python version in the same YAML configuration file used to set your hyperparameter tuning settings. See how to submit a training job using Python 3.5."]},{"metadata":{"id":"PKraT3OciTbi","colab_type":"text"},"cell_type":"markdown","source":["### GPUs\n","\n","Cloud ML Engine offers machines with graphics processing units (GPUs) that you can request to help scale your training job. For more information about GPUs, see [Using GPUs.](https://cloud.google.com/ml-engine/docs/tensorflow/using-gpus?authuser=0&hl=ko)"]},{"metadata":{"id":"rzwZ2re9ilEF","colab_type":"text"},"cell_type":"markdown","source":["## Deploy a model to support prediction"]},{"metadata":{"id":"d6KFw0DKil6Z","colab_type":"text"},"cell_type":"markdown","source":["1.Choose a name for your model; this must start with a letter and contain only letters, numbers, and underscores. For example:"]},{"metadata":{"id":"mAOjMjfuhM11","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['MODEL_NAME']=\"census\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"x6h7E7aya_KO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"10ea4267-4eed-4cba-ffba-3225a1982a4c","executionInfo":{"status":"ok","timestamp":1525408356683,"user_tz":-540,"elapsed":1737,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!echo $MODEL_NAME"],"execution_count":27,"outputs":[{"output_type":"stream","text":["census\r\n"],"name":"stdout"}]},{"metadata":{"id":"ssbSn6mwiraQ","colab_type":"text"},"cell_type":"markdown","source":["2.Create a Cloud ML Engine model:"]},{"metadata":{"id":"OoppFBrQhcmZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":87},"outputId":"2fa16685-b243-49cd-c2f3-5c80ff1abae1","executionInfo":{"status":"ok","timestamp":1525410386803,"user_tz":-540,"elapsed":2714,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine models list"],"execution_count":44,"outputs":[{"output_type":"stream","text":["NAME      DEFAULT_VERSION_NAME\r\n","census\r\n","taxifare  v1\r\n"],"name":"stdout"}]},{"metadata":{"id":"x4Y2Ve10h_kW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":120},"outputId":"2fbed0fc-69ab-498a-e034-658dc83a663d","executionInfo":{"status":"ok","timestamp":1525410186886,"user_tz":-540,"elapsed":3171,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gsutil ls gs://cpb100-182208/census_core_hptune_1"],"execution_count":36,"outputs":[{"output_type":"stream","text":["gs://cpb100-182208/census_core_hptune_1/1/\r\n","gs://cpb100-182208/census_core_hptune_1/2/\r\n","gs://cpb100-182208/census_core_hptune_1/3/\r\n","gs://cpb100-182208/census_core_hptune_1/4/\r\n","gs://cpb100-182208/census_core_hptune_1/packages/\r\n"],"name":"stdout"}]},{"metadata":{"id":"KhfVT056iqN3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"be87fe60-7869-4ff1-adcc-c8bc8d01fa16","executionInfo":{"status":"ok","timestamp":1525410316115,"user_tz":-540,"elapsed":3270,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gcloud ml-engine models create $MODEL_NAME --regions=us-central1"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Created ml engine model [projects/cpb100-182208/models/census].\r\n"],"name":"stdout"}]},{"metadata":{"id":"SKe6EYbGi1CW","colab_type":"text"},"cell_type":"markdown","source":["3.Select the job output to use. The following sample uses the job named census_dist_1."]},{"metadata":{"id":"rG_JfIt7i1zB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['OUTPUT_PATH']=\"gs://cpb100-182208/census_dist_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xYdkuZt2i-FH","colab_type":"text"},"cell_type":"markdown","source":["4.Look up the full path of your exported trained model binaries:"]},{"metadata":{"id":"T7BYI8cfi8CK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"11de71cb-5721-4b73-d95a-e2e7282d589c","executionInfo":{"status":"ok","timestamp":1525410366904,"user_tz":-540,"elapsed":2980,"user":{"displayName":"John Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100225940964623691936"}}},"cell_type":"code","source":["!gsutil ls -r $OUTPUT_PATH/export"],"execution_count":42,"outputs":[{"output_type":"stream","text":["CommandException: One or more URLs matched no objects.\r\n"],"name":"stdout"}]},{"metadata":{"id":"i92HkrKnjBzB","colab_type":"text"},"cell_type":"markdown","source":["5.Find a directory named $OUTPUT_PATH/export/census/<timestamp> and copy this directory path (without the : at the end) and set the environment variable MODEL_BINARIES to its value. For example:"]},{"metadata":{"id":"t5WJL3WDjAYQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['MODEL_BINARIES']=\"gs://cpb100-182208/census_dist_1/export/census/1487877383942/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"lA1Q6aCdjQf_","colab_type":"text"},"cell_type":"markdown","source":["Where $BUCKET_NAME is your Cloud Storage bucket name, and census_dist_1 is the output directory."]},{"metadata":{"id":"qhr6akjPjSs8","colab_type":"text"},"cell_type":"markdown","source":["6.Run the following command to create a version v1:"]},{"metadata":{"id":"OJaMNierjOIn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gcloud ml-engine versions create v1 \\\n","--model $MODEL_NAME \\\n","--origin $MODEL_BINARIES \\\n","--runtime-version 1.4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ctaEvAgsjXwC","colab_type":"text"},"cell_type":"markdown","source":["You can get a list of your models using the models list command."]},{"metadata":{"id":"nlhwVt_9jYW6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gcloud ml-engine models list"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iBTFf58fjcZK","colab_type":"text"},"cell_type":"markdown","source":["## Send a prediction request to a deployed model\n","\n","You can now send prediction requests to your model. For example, the following command sends a prediction request using a test.json file that you downloaded as part of the sample GitHub repository."]},{"metadata":{"id":"hihwbWnrjfsg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gcloud ml-engine predict \\\n","--model $MODEL_NAME \\\n","--version v1 \\\n","--json-instances \\\n","cloudml-samples-master/census/test.json"],"execution_count":0,"outputs":[]},{"metadata":{"id":"93v9XkIzjqCa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!ls -al cloudml-samples-master/census/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"THhmfH-RjpiB","colab_type":"text"},"cell_type":"markdown","source":["The response includes the predicted labels of the examples."]},{"metadata":{"id":"suaiVptTjroJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["CLASS_IDS  CLASSES  LOGISTIC                LOGITS                PROBABILITIES\n","[0]        [u'0']   [0.014086329378187656]  [-4.248363971710205]  [0.9859136939048767, 0.014086330309510231]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XiTdgdytj2LS","colab_type":"text"},"cell_type":"markdown","source":["### Submit a batch prediction job\n","\n","The batch prediction service is useful if you have large amounts of data, and no latency requirements on receiving prediction results. This uses the same format as online prediction, but requires data be stored in Cloud Storage."]},{"metadata":{"id":"5v__jpB9j9lU","colab_type":"text"},"cell_type":"markdown","source":["1.Set a name for the job."]},{"metadata":{"id":"lqMJc1fbj5MU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['JOB_NAME']=\"census_prediction_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"iXXovZI7kBy4","colab_type":"text"},"cell_type":"markdown","source":["2.Set the output path."]},{"metadata":{"id":"1I1SWgYIkAtb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.environ['OUTPUT_PATH']=\"gs://cpb100-182208/census_prediction_1\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"NfVSLk3zkMre","colab_type":"text"},"cell_type":"markdown","source":["3.Submit the prediction job."]},{"metadata":{"id":"yaRVNjavkKLJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gcloud ml-engine jobs submit prediction $JOB_NAME \\\n","    --model $MODEL_NAME \\\n","    --version v1 \\\n","    --data-format TEXT \\\n","    --region $REGION \\\n","    --input-paths $TEST_JSON \\\n","    --output-path $OUTPUT_PATH/predictions"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EDlvcyAckTAv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!echo $TEST_JSON"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AxRerMtHkSjw","colab_type":"text"},"cell_type":"markdown","source":["Unlike the previous commands, this one returns immediately. Check the progress of the job and wait for it to finish:"]},{"metadata":{"id":"dWn2BG1QkWcQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gcloud ml-engine jobs describe $JOB_NAME"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zxL5vXjxkaUO","colab_type":"text"},"cell_type":"markdown","source":["You should see state: SUCCEEDED once the job completes; this may take several minutes. You can also see the job logs in your terminal using"]},{"metadata":{"id":"ZROZa8j3kdFH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gcloud ml-engine jobs stream-logs $JOB_NAME"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8sGoeeZdkfKl","colab_type":"text"},"cell_type":"markdown","source":["Alternatively, you can check the progress in ML Engine > Jobs on [GCP Console](https://console.cloud.google.com/ml/jobs?authuser=0&hl=ko&_ga=2.221226392.-1080636544.1524192810)."]},{"metadata":{"id":"09ZA2Qioklx1","colab_type":"text"},"cell_type":"markdown","source":["After the job succeeds, you can:\n","\n","* Read the output summary."]},{"metadata":{"id":"POhiMvkBkkJ1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gsutil cat $OUTPUT_PATH/predictions/prediction.results-00000-of-00001"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AcdJveT1kql5","colab_type":"text"},"cell_type":"markdown","source":["You should see output similar to the following."]},{"metadata":{"id":"2kJzXK44krUD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#{\"probabilities\": [0.9962924122810364, 0.003707568161189556], \"logits\": [-5.593664646148682], \"classes\": 0, \"logistic\": [0.003707568161189556]}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wu8zoSFlkq9e","colab_type":"text"},"cell_type":"markdown","source":["List the other files that the job produced using the gsutil ls command."]},{"metadata":{"id":"ihtghLl4kw2G","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!gsutil ls -r $OUTPUT_PATH"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bsTpcQkHkwV0","colab_type":"text"},"cell_type":"markdown","source":["Compared to online prediction, batch prediction:\n","\n","* Is slower for this small number of instances (but is more suitable for large numbers of instances).\n","* Could return output in a different order than the input (but the numeric index allows each output to be matched to its corresponding input instance; this is not necessary for online prediction since the outputs are returned in the same order as the original input instances)\n","\n","온라인 예측에 대한 배치 예측비교  :\n","\n","* 인스턴스 수가 적으면 속도가 느립니다 (인스턴스 수가 많을수록 더 적합합니다).\n","* 출력은 입력과 다른 순서로 반환 될 수 있지만 (숫자 인덱스를 사용하면 각 출력을 해당 입력 인스턴스와 일치시킬 수 있으며 출력은 원래 입력 인스턴스와 동일한 순서로 반환되기 때문에 온라인 예측에는 필요하지 않음)\n","\n","예측이 가능해지면 다음 단계는 대개 이러한 예측을 데이터베이스 또는 데이터 처리 파이프 라인으로 가져 오는 것입니다.\n","\n","이 샘플에서는 배치 예측을 실행하기 전에 모델을 배포했지만 배치 예측 작업을 제출할 때 모델 바이너리 URI를 지정하여 해당 단계를 건너 뛸 수 있습니다. 모델을 배포하기 전에 모델에서 예측을 생성하는 한 가지 장점은 모델이 배포 기준을 충족하는지 여부를 판단하는데 도움이되도록 여러 평가 데이터 세트에서 모델의 성능을 평가할 수 있다는 것입니다."]},{"metadata":{"id":"1hvWV9BXlZxX","colab_type":"text"},"cell_type":"markdown","source":["### Clean up\n","\n","If you are done analyzing the output from your training and prediction runs, you can avoid incurring additional charges to your Google Cloud Platform account for the Cloud Storage directories used in this guide:\n","\n","1. Open a terminal window (if not already open).\n","2. Use the gsutil rm command with the -r flag to delete the directory that contains your most recent job:"]},{"metadata":{"id":"uePdd_s_lG4Y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#gsutil rm -r gs://$BUCKET_NAME/$JOB_NAME"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p4lBiIv5ldnX","colab_type":"text"},"cell_type":"markdown","source":["Repeat the command for any other directories that you created for this sample.\n","\n","Alternatively, if you have no other data stored in the bucket, you can run the gsutil rm -r command on the bucket itself."]},{"metadata":{"id":"9Xuokymjlucg","colab_type":"text"},"cell_type":"markdown","source":["## What's next\n","\n","You've now completed a walkthrough of a Cloud ML Engine sample that uses census data for training and prediction. You validated the trainer locally, ran it in the cloud in both single-instance and distributed mode, used hyperparameter tuning to improve the model, and used the model to get online and batch predictions.\n","\n","The following resources can help you continue learning about Cloud ML Engine.\n","\n","* [Learn about the basics of Cloud ML Engine](https://cloud.google.com/ml-engine/docs/tensorflow/technical-overview?authuser=0&hl=ko)\n","* [See an example that trains and predicts using low-level TensorFlow.](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/)"]},{"metadata":{"id":"RKl18MFSlhKc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!open "],"execution_count":0,"outputs":[]}]}